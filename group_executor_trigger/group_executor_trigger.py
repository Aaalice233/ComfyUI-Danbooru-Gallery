"""
ä¼˜åŒ–ç»„æ‰§è¡Œè§¦å‘å™¨ - Optimized Group Executor Trigger
åŸºäºComfyUIåŸç”Ÿæœºåˆ¶å®Œå…¨é‡å†™ï¼Œä½¿ç”¨STRINGç±»å‹æ¥æ”¶JSONæ‰§è¡Œè®¡åˆ’

âš ï¸ å…³é”®ä¿®æ­£ï¼š
1. ä½¿ç”¨STRINGç±»å‹æ¥æ”¶JSONåºåˆ—åŒ–çš„æ‰§è¡Œè®¡åˆ’å’Œæ§åˆ¶ä¿¡å·
2. ä¸“æ³¨äºWebSocketæ¶ˆæ¯è§¦å‘å’Œå®¢æˆ·ç«¯éš”ç¦»
3. å¢å¼ºé”™è¯¯å¤„ç†å’ŒçŠ¶æ€æŠ¥å‘Š
4. ä¿æŒä¸ç°æœ‰å·¥ä½œæµçš„å®Œå…¨å…¼å®¹æ€§
"""

import json
import time
import logging
from typing import Dict, Any
try:
    from server import PromptServer
except ImportError:
    PromptServer = None

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("OptimizedGET")


# âœ… å…¨å±€æ‰§è¡ŒçŠ¶æ€è¿½è¸ª - é˜²æ­¢é‡å¤æ‰§è¡ŒåŒä¸€execution_id
_execution_status_tracker = {}
_status_lock = None

try:
    import threading
    _status_lock = threading.Lock()
except:
    pass


def get_execution_status(execution_id):
    """è·å–execution_idçš„çŠ¶æ€"""
    if _status_lock:
        with _status_lock:
            return _execution_status_tracker.get(execution_id, {})
    return _execution_status_tracker.get(execution_id, {})


class AnyType(str):
    """ç”¨äºè¡¨ç¤ºä»»æ„ç±»å‹çš„ç‰¹æ®Šç±»ï¼Œåœ¨ç±»å‹æ¯”è¾ƒæ—¶æ€»æ˜¯è¿”å›Falseï¼ˆä¸ç›¸ç­‰ï¼‰"""
    def __ne__(self, __value: object) -> bool:
        return False


any_typ = AnyType("*")


class GroupExecutorTrigger:
    """
    åŸºäºComfyUIåŸç”Ÿæœºåˆ¶çš„ç»„æ‰§è¡Œè§¦å‘å™¨

    âš ï¸ å…³é”®ä¿®æ­£ï¼š
    1. ä½¿ç”¨STRINGç±»å‹æ¥æ”¶JSONåºåˆ—åŒ–çš„æ‰§è¡Œè®¡åˆ’å’Œæ§åˆ¶ä¿¡å·
    2. ä¸“æ³¨äºWebSocketæ¶ˆæ¯è§¦å‘å’Œå®¢æˆ·ç«¯éš”ç¦»
    3. å¢å¼ºé”™è¯¯å¤„ç†å’ŒçŠ¶æ€æŠ¥å‘Š
    4. ä¿æŒä¸ç°æœ‰å·¥ä½œæµçš„å®Œå…¨å…¼å®¹æ€§
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "execution_plan": ("STRING", {
                    "forceInput": True,
                    "tooltip": "ä»GroupExecutorManageræ¥æ”¶çš„æ‰§è¡Œè®¡åˆ’"
                }),
                "cache_control_signal": ("STRING", {
                    "forceInput": True,
                    "tooltip": "ä»GroupExecutorManageræ¥æ”¶çš„ç¼“å­˜æ§åˆ¶ä¿¡å·"
                }),
                "signal": (any_typ, {}),  # âœ… æŒ‰å®˜æ–¹æ–‡æ¡£æ ¼å¼ï¼š("*", {})
            },
            "optional": {},
            "hidden": {
                "unique_id": "UNIQUE_ID",
                "client_id": "CLIENT_ID"
            }
        }

    RETURN_TYPES = ("STRING", any_typ)  # âœ… ä¿®å¤ï¼šè¿”å›STRINGå’Œä»»æ„ç±»å‹ä¿¡å·ç”¨äºå»ºç«‹æ‰§è¡Œä¾èµ–
    RETURN_NAMES = ("execution_status", "signal_output")
    FUNCTION = "trigger_optimized_execution"
    CATEGORY = "danbooru"
    OUTPUT_NODE = True  # ä¿æŒè¾“å‡ºèŠ‚ç‚¹å±æ€§ä»¥å‘é€WebSocketæ¶ˆæ¯
    OUTPUT_IS_LIST = (False, False)  # ä¸¤ä¸ªè¾“å‡ºéƒ½ä¸æ˜¯åˆ—è¡¨

    @classmethod
    def VALIDATE_INPUTS(cls, input_types):
        """è·³è¿‡wildcardç±»å‹çš„åç«¯éªŒè¯"""
        return True

    def trigger_optimized_execution(self,
                                execution_plan: str,
                                cache_control_signal: str,
                                signal=None,
                                unique_id=None,
                                client_id=None) -> dict:
        """
        è§¦å‘ä¼˜åŒ–ç»„æ‰§è¡Œ - å‘é€WebSocketæ¶ˆæ¯åˆ°JavaScriptå¼•æ“

        Returns:
            dict: åŒ…å«execution_statuså’Œsignal_outputçš„å­—å…¸
        """

        start_time = time.time()

        try:
            # ğŸ“¥ è¾“å…¥æ—¥å¿—ï¼šæ˜¾ç¤ºä»GroupExecutorManageræ¥æ”¶åˆ°çš„å†…å®¹
            logger.info(f"\n{'='*80}")
            logger.info(f"[GroupExecutorTrigger] ğŸ“¥ æ¥æ”¶åˆ°æ¥è‡ªGroupExecutorManagerçš„æ•°æ®")
            logger.info(f"[GroupExecutorTrigger] ğŸ“ è¾“å…¥å†…å®¹:")
            logger.info(f"   â”œâ”€ execution_plan (STRING):")
            logger.info(f"   â”‚  {execution_plan[:200]}{'...' if len(execution_plan) > 200 else ''}")
            logger.info(f"   â”œâ”€ cache_control_signal (STRING):")
            logger.info(f"   â”‚  {cache_control_signal[:200]}{'...' if len(cache_control_signal) > 200 else ''}")
            logger.info(f"   â””â”€ signal: {type(signal).__name__} = {signal}")
            logger.info(f"{'='*80}\n")

            # å¤„ç†å¯é€‰å‚æ•°
            unique_id = unique_id or "unknown"
            
            # âœ… ä¿®å¤ï¼šç›´æ¥ä»PromptServer.instanceè·å–çœŸå®client_id
            # ä¸ä¾èµ–hiddenå‚æ•°ï¼ˆCLIENT_IDå¯èƒ½ä¸è¢«æ”¯æŒï¼‰
            # å› ä¸ºexecute_asyncå·²ç»åœ¨execution.pyä¸­è®¾ç½®äº†client_id
            real_client_id = PromptServer.instance.client_id if PromptServer else None
            if not real_client_id:
                # å¦‚æœè·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ä¼ å…¥çš„å‚æ•°
                real_client_id = client_id or "unknown"

            # 1. è§£ææ‰§è¡Œè®¡åˆ’å’Œæ§åˆ¶ä¿¡å·
            execution_plan_dict = json.loads(execution_plan)
            cache_control_signal_dict = json.loads(cache_control_signal)

            execution_id = execution_plan_dict.get("execution_id", "unknown")
            
            # âœ… ä¿®å¤ï¼šè¦†ç›–execution_plançš„client_idä¸ºçœŸå®å€¼
            execution_plan_dict["client_id"] = real_client_id

            # âœ… æ–°å¢ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤çš„execution_id
            # é˜²æ­¢åŒä¸€ä¸ªexecutionåœ¨çŸ­æ—¶é—´å†…è¢«å¤šæ¬¡è§¦å‘
            last_status = get_execution_status(execution_id)
            if last_status:
                elapsed = time.time() - last_status.get("trigger_time", 0)
                # å¦‚æœåœ¨30ç§’å†…é‡å¤è§¦å‘åŒä¸€ä¸ªexecution_idï¼Œè¯´æ˜æ˜¯GroupExecutorTriggerè¢«é‡å¤æ‰§è¡Œ
                # è¿™é€šå¸¸å‘ç”Ÿåœ¨GroupExecutorManagerè¾“å‡ºé¢‘ç¹å˜åŒ–æ—¶
                if elapsed < 30:
                    logger.warning(f"[GroupExecutorTrigger] âš ï¸ æ£€æµ‹åˆ°é‡å¤çš„execution_id: {execution_id} (è·ç¦»ä¸Šæ¬¡è§¦å‘{elapsed:.1f}ç§’)")
                    logger.warning(f"[GroupExecutorTrigger] âš ï¸ å·²å­˜å‚¨çŠ¶æ€: {last_status}")
                    logger.warning(f"[GroupExecutorTrigger] âš ï¸ è·³è¿‡é‡å¤æ‰§è¡Œï¼Œè¿”å›ä¹‹å‰çš„çŠ¶æ€")
                    return (json.dumps({
                        "status": "skipped_duplicate",
                        "execution_id": execution_id,
                        "message": "è·³è¿‡é‡å¤çš„executionè¯·æ±‚",
                        "timestamp": time.time()
                    }, ensure_ascii=False), signal)
            
            # âœ… è®°å½•executionå¼€å§‹æ—¶é—´
            if _status_lock:
                with _status_lock:
                    _execution_status_tracker[execution_id] = {
                        "trigger_time": time.time(),
                        "client_id": real_client_id,
                        "status": "triggered",
                        "groups_count": len(execution_plan_dict.get("groups", []))
                    }
            else:
                _execution_status_tracker[execution_id] = {
                    "trigger_time": time.time(),
                    "client_id": real_client_id,
                    "status": "triggered",
                    "groups_count": len(execution_plan_dict.get("groups", []))
                }

            # ä½¿ç”¨é»˜è®¤å€¼
            force_execution = False
            pause_on_error = True
            execution_priority = "normal"
            execution_timeout = 300

            logger.info(f"[GroupExecutorTrigger] â° æ‰§è¡Œæ—¶é—´: {time.strftime('%H:%M:%S', time.localtime())}")
            logger.info(f"[GroupExecutorTrigger] ğŸš€ å¼€å§‹æ‰§è¡Œç»„è®¡åˆ’")
            logger.info(f"[GroupExecutorTrigger] ğŸ”§ æ‰§è¡ŒID: {execution_id}")
            logger.info(f"[GroupExecutorTrigger] ğŸ–¥ï¸  å®¢æˆ·ç«¯ID: {real_client_id}")
            logger.info(f"[GroupExecutorTrigger] ğŸ“‹ èŠ‚ç‚¹ID: {unique_id}")
            logger.info(f"{'='*80}\n")

            # 2. éªŒè¯æ‰§è¡Œè®¡åˆ’
            validation_result = self.validate_execution_plan(execution_plan_dict, cache_control_signal_dict, real_client_id)
            if not validation_result["valid"]:
                error_msg = f"æ‰§è¡Œè®¡åˆ’éªŒè¯å¤±è´¥: {validation_result['errors']}"
                logger.error(f"[GroupExecutorTrigger] âŒ {error_msg}")
                return self.create_error_status(execution_id, error_msg, start_time, signal)

            # 3. æ£€æŸ¥æ‰§è¡Œæƒé™å’Œå¼ºåˆ¶æ‰§è¡Œæ ‡å¿—
            if not force_execution and not self.check_execution_permission(cache_control_signal_dict, execution_id):
                warning_msg = "æ‰§è¡Œæƒé™ä¸è¶³ï¼Œéœ€è¦å¼ºåˆ¶æ‰§è¡Œæˆ–ç­‰å¾…ç¼“å­˜æ§åˆ¶ä¿¡å·"
                logger.warning(f"[GroupExecutorTrigger] âš ï¸ {warning_msg}")
                return self.create_warning_status(execution_id, warning_msg, start_time, signal)

            # 4. å‘é€WebSocketæ¶ˆæ¯ç»™JavaScriptå¼•æ“
            message_data = {
                "type": "danbooru_optimized_execution",
                "execution_id": execution_id,
                "execution_plan": execution_plan_dict,
                "cache_control_signal": cache_control_signal_dict,
                "trigger_config": {
                    "force_execution": force_execution,
                    "pause_on_error": pause_on_error,
                    "execution_priority": execution_priority,
                    "execution_timeout": execution_timeout
                },
                "client_id": real_client_id,
                "node_id": unique_id,
                "timestamp": start_time
            }

            logger.info(f"[GroupExecutorTrigger] ğŸ“¡ å‘é€WebSocketæ¶ˆæ¯:")
            logger.info(f"   - äº‹ä»¶ç±»å‹: {message_data['type']}")
            logger.info(f"   - æ‰§è¡ŒID: {execution_id}")
            logger.info(f"   - ç»„æ•°é‡: {len(execution_plan_dict.get('groups', []))}")
            logger.info(f"   - å®¢æˆ·ç«¯ID: {real_client_id}")
            logger.info(f"   - å¼ºåˆ¶æ‰§è¡Œ: {force_execution}")

            # 5. å‘é€æ¶ˆæ¯åˆ°å‰ç«¯JavaScriptå¼•æ“
            PromptServer.instance.send_sync("danbooru_optimized_execution", message_data, PromptServer.instance.client_id)

            logger.info(f"[GroupExecutorTrigger] âœ… WebSocketæ¶ˆæ¯å‘é€æˆåŠŸ")
            logger.info(f"[GroupExecutorTrigger] â³ JavaScriptå¼•æ“å°†å¼‚æ­¥æ‰§è¡Œç»„åˆ—è¡¨\n")

            # 6. åˆ›å»ºUIæ•°æ®å¹¶å­˜å‚¨åˆ°èŠ‚ç‚¹
            ui_data = {
                "current_group": execution_plan_dict.get("groups", [{}])[0].get("name", "æœªå¼€å§‹"),
                "group_list": [group.get("name", f"ç»„ {i+1}") for i, group in enumerate(execution_plan_dict.get("groups", []))],
                "current_nodes": execution_plan_dict.get("groups", [{}])[0].get("nodes", []),
                "execution_mode": execution_plan_dict.get("mode", "sequential"),
                "status": "executing",
                "execution_id": execution_id
            }

            # å°†UIæ•°æ®å­˜å‚¨åˆ°èŠ‚ç‚¹å±æ€§ï¼Œä¾›UIç»„ä»¶ä½¿ç”¨
            self._ui_data = ui_data

            # 7. åˆ›å»ºæ‰§è¡ŒçŠ¶æ€æ—¥å¿—
            execution_status = {
                "status": "triggered",
                "execution_id": execution_id,
                "message": "æ‰§è¡Œå·²è§¦å‘ï¼Œç­‰å¾…JavaScriptå¼•æ“å¤„ç†",
                "timestamp": start_time,
                "client_id": real_client_id,
                "node_id": unique_id,
                "execution_priority": execution_priority,
                "execution_timeout": execution_timeout
            }

            logger.info(f"[GroupExecutorTrigger] ğŸ“Š UIæ•°æ®å·²å‡†å¤‡å°±ç»ªï¼Œå½“å‰ç»„: {ui_data['current_group']}")

            # âœ… ä¿®å¤ï¼šè¿”å›execution_statuså­—ç¬¦ä¸²ç”¨äºå»ºç«‹æ‰§è¡Œä¾èµ–
            status_json = json.dumps({
                "status": "triggered",
                "execution_id": execution_id,
                "timestamp": start_time
            }, ensure_ascii=False)

            # âœ… ä¿®å¤ï¼šç›´æ¥è¿”å›å…ƒç»„ï¼Œè®©signalæ²¿é“¾ä¼ é€’
            # å½“OUTPUT_NODE=Trueæ—¶ï¼ŒComfyUIä¼šè‡ªåŠ¨å¤„ç†uiæ˜¾ç¤º
            return (status_json, signal)

        except json.JSONDecodeError as e:
            error_msg = f"JSONè§£æå¤±è´¥: {str(e)}"
            logger.error(f"[GroupExecutorTrigger] âŒ {error_msg}")
            return self.create_error_status("unknown", error_msg, start_time, signal)

        except Exception as e:
            error_msg = f"è§¦å‘æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(f"[GroupExecutorTrigger] âŒ {error_msg}")
            import traceback
            logger.error(f"[GroupExecutorTrigger] é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
            return self.create_error_status("unknown", error_msg, start_time, signal)

    def validate_execution_plan(self, execution_plan: Dict, cache_control_signal: Dict, client_id: str) -> Dict[str, Any]:
        """
        éªŒè¯æ‰§è¡Œè®¡åˆ’çš„æœ‰æ•ˆæ€§

        Args:
            execution_plan: æ‰§è¡Œè®¡åˆ’å­—å…¸
            cache_control_signal: ç¼“å­˜æ§åˆ¶ä¿¡å·å­—å…¸
            client_id: å®¢æˆ·ç«¯ID

        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        errors = []

        # ğŸ“‹ è¾“å‡ºæ‰§è¡Œè®¡åˆ’å’Œç¼“å­˜ä¿¡å·å†…å®¹
        logger.info(f"[GroupExecutorTrigger] ğŸ“‹ æ‰§è¡Œè®¡åˆ’å†…å®¹:")
        logger.info(f"   - æ‰§è¡ŒID: {execution_plan.get('execution_id')}")
        logger.info(f"   - ç»„æ•°é‡: {len(execution_plan.get('groups', []))}")
        logger.info(f"   - æ‰§è¡Œæ¨¡å¼: {execution_plan.get('execution_mode')}")
        logger.info(f"   - ç¼“å­˜æ§åˆ¶æ¨¡å¼: {execution_plan.get('cache_control_mode')}")
        logger.info(f"   - å®¢æˆ·ç«¯ID: {execution_plan.get('client_id')}")
        
        # æ˜¾ç¤ºå…·ä½“çš„ç»„ä¿¡æ¯
        groups = execution_plan.get("groups", [])
        for i, group in enumerate(groups):
            group_name = group.get("group_name", group.get("name", f"ç»„{i+1}"))
            group_nodes = group.get("nodes", [])
            logger.info(f"   - ç»„{i+1}: {group_name} (åŒ…å«{len(group_nodes)}ä¸ªèŠ‚ç‚¹)")
        
        logger.info(f"[GroupExecutorTrigger] ğŸ“‹ ç¼“å­˜ä¿¡å·å†…å®¹:")
        logger.info(f"   - æ‰§è¡ŒID: {cache_control_signal.get('execution_id')}")
        logger.info(f"   - ç¼“å­˜æ§åˆ¶æ¨¡å¼: {cache_control_signal.get('cache_control_mode')}")
        logger.info(f"   - å¯ç”¨ç¼“å­˜: {cache_control_signal.get('enable_cache')}")
        logger.info(f"   - å¯ç”¨æ‰§è¡Œ(enabled): {cache_control_signal.get('enabled')}")
        logger.info(f"   - æ—¶é—´æˆ³: {cache_control_signal.get('timestamp')}")
        logger.info(f"   - æ‰€æœ‰å­—æ®µ: {list(cache_control_signal.keys())}")

        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        required_fields = ["execution_id", "groups", "execution_mode", "cache_control_mode"]
        for field in required_fields:
            if field not in execution_plan:
                errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")

        # æ£€æŸ¥ç»„é…ç½®
        groups = execution_plan.get("groups", [])
        if not isinstance(groups, list):
            errors.append("groupså­—æ®µå¿…é¡»æ˜¯æ•°ç»„")
        elif len(groups) == 0:
            errors.append("groupsæ•°ç»„ä¸èƒ½ä¸ºç©º")

        # æ£€æŸ¥æ‰§è¡Œæ¨¡å¼
        execution_mode = execution_plan.get("execution_mode", "")
        if execution_mode not in ["sequential", "parallel"]:
            errors.append(f"æ— æ•ˆçš„æ‰§è¡Œæ¨¡å¼: {execution_mode}")

        # æ£€æŸ¥ç¼“å­˜æ§åˆ¶æ¨¡å¼
        cache_control_mode = execution_plan.get("cache_control_mode", "")
        if cache_control_mode not in ["block_until_allowed", "always_allow", "conditional"]:
            errors.append(f"æ— æ•ˆçš„ç¼“å­˜æ§åˆ¶æ¨¡å¼: {cache_control_mode}")

        # âœ… æ£€æŸ¥execution_idåŒ¹é…ï¼ˆç¡®ä¿ä¸¤ä¸ªä¿¡å·æ¥è‡ªåŒä¸€æ‰¹æ“ä½œï¼‰
        signal_execution_id = cache_control_signal.get("execution_id", "")
        if signal_execution_id != execution_plan.get("execution_id", ""):
            errors.append(f"æ‰§è¡ŒIDä¸åŒ¹é…: è®¡åˆ’={execution_plan.get('execution_id')}, ä¿¡å·={signal_execution_id}")

        # âœ… ä¿®å¤ï¼šæ¢å¤client_idçš„ä¸¥æ ¼éªŒè¯
        # å› ä¸ºsend_syncç°åœ¨ä½¿ç”¨sidå‚æ•°æ­£ç¡®åœ°éš”ç¦»ï¼Œå‰ç«¯åªä¼šæ¥æ”¶åˆ°æ­£ç¡®çš„client_id
        plan_client_id = execution_plan.get("client_id", "")
        if plan_client_id and plan_client_id != client_id:
            errors.append(f"å®¢æˆ·ç«¯IDä¸åŒ¹é…: è®¡åˆ’={plan_client_id}, å½“å‰={client_id}")

        if errors:
            logger.error(f"[GroupExecutorTrigger] âŒ éªŒè¯å¤±è´¥ï¼Œå…±{len(errors)}ä¸ªé”™è¯¯:")
            for error in errors:
                logger.error(f"   - {error}")

        return {"valid": len(errors) == 0, "errors": errors}

    def check_execution_permission(self, cache_control_signal: Dict, execution_id: str) -> bool:
        """
        æ£€æŸ¥æ‰§è¡Œæƒé™

        Args:
            cache_control_signal: ç¼“å­˜æ§åˆ¶ä¿¡å·
            execution_id: æ‰§è¡ŒID

        Returns:
            æ˜¯å¦å…è®¸æ‰§è¡Œ
        """
        logger.info(f"[GroupExecutorTrigger] ğŸ” å¼€å§‹æ£€æŸ¥æ‰§è¡Œæƒé™...")
        logger.info(f"   - æœŸæœ›æ‰§è¡ŒID: {execution_id}")
        logger.info(f"   - ç¼“å­˜ä¿¡å·å†…å®¹: {cache_control_signal}")
        
        # æ£€æŸ¥æ§åˆ¶ä¿¡å·æœ‰æ•ˆæ€§
        if not cache_control_signal.get("valid", True):
            logger.warning(f"[GroupExecutorTrigger] âš ï¸ ç¼“å­˜æ§åˆ¶ä¿¡å·æ— æ•ˆ: {cache_control_signal.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return False

        # æ£€æŸ¥æ‰§è¡ŒIDåŒ¹é…
        signal_execution_id = cache_control_signal.get("execution_id", "")
        if signal_execution_id != execution_id:
            logger.warning(f"[GroupExecutorTrigger] âš ï¸ æ‰§è¡ŒIDä¸åŒ¹é…: ä¿¡å·={signal_execution_id}, è®¡åˆ’={execution_id}")
            return False

        # æ£€æŸ¥å¯ç”¨çŠ¶æ€
        enabled = cache_control_signal.get("enabled", False)
        logger.info(f"   - å¯ç”¨çŠ¶æ€(enabled): {enabled}")
        if not enabled:
            logger.warning(f"[GroupExecutorTrigger] âš ï¸ ç¼“å­˜æ§åˆ¶ä¿¡å·ç¦ç”¨æ‰§è¡Œ")
            return False

        # æ£€æŸ¥æ—¶é—´æˆ³ï¼ˆé¿å…ä½¿ç”¨è¿‡æœŸä¿¡å·ï¼‰
        signal_timestamp = cache_control_signal.get("timestamp", 0)
        current_time = time.time()
        time_diff = current_time - signal_timestamp
        logger.info(f"   - ä¿¡å·æ—¶é—´æˆ³: {signal_timestamp}")
        logger.info(f"   - å½“å‰æ—¶é—´: {current_time}")
        logger.info(f"   - æ—¶é—´å·®: {time_diff:.1f}ç§’")
        
        if time_diff > 600:  # 10åˆ†é’Ÿè¶…æ—¶
            logger.warning(f"[GroupExecutorTrigger] â° ç¼“å­˜æ§åˆ¶ä¿¡å·è¿‡æœŸ: {time_diff:.1f}ç§’ > 600ç§’")
            return False
        
        logger.info(f"[GroupExecutorTrigger] âœ… æ‰€æœ‰æƒé™æ£€æŸ¥é€šè¿‡ï¼")
        return True

    def create_error_status(self, execution_id: str, error_message: str, timestamp: float, signal) -> tuple:
        """
        åˆ›å»ºé”™è¯¯çŠ¶æ€è¿”å›å€¼

        Args:
            execution_id: æ‰§è¡ŒID
            error_message: é”™è¯¯æ¶ˆæ¯
            timestamp: æ—¶é—´æˆ³

        Returns:
            åŒ…å«é”™è¯¯çŠ¶æ€JSONçš„å…ƒç»„
        """
        error_status = {
            "status": "error",
            "execution_id": execution_id,
            "error": error_message,
            "timestamp": timestamp,
            "error_type": "validation_error"
        }

        status_json = json.dumps(error_status, ensure_ascii=False)
        # âœ… ä¿®å¤ï¼šè¿”å›å…ƒç»„æ ¼å¼ï¼Œç¬¬äºŒä¸ªå…ƒç´ ä¸ºNoneè¡¨ç¤ºä¼ é€’ä¸­æ–­
        return (status_json, signal)

    def create_warning_status(self, execution_id: str, warning_message: str, timestamp: float, signal):
        """
        åˆ›å»ºè­¦å‘ŠçŠ¶æ€è¿”å›å€¼

        Args:
            execution_id: æ‰§è¡ŒID
            warning_message: è­¦å‘Šæ¶ˆæ¯
            timestamp: æ—¶é—´æˆ³

        Returns:
            åŒ…å«è­¦å‘ŠçŠ¶æ€JSONçš„å…ƒç»„
        """
        warning_status = {
            "status": "warning",
            "execution_id": execution_id,
            "message": warning_message,
            "timestamp": timestamp,
            "warning_type": "permission_denied"
        }

        status_json = json.dumps(warning_status, ensure_ascii=False)
        # âœ… ä¿®å¤ï¼šè¿”å›å…ƒç»„æ ¼å¼ï¼Œç¬¬äºŒä¸ªå…ƒç´ ä¸ºNoneè¡¨ç¤ºæœªèƒ½é€šè¿‡æƒé™æ£€æŸ¥
        return (status_json, signal)

# èŠ‚ç‚¹æ˜ å°„å¯¼å‡ºå‡½æ•°
def get_node_class_mappings():
    return {
        "GroupExecutorTrigger": GroupExecutorTrigger
    }

def get_node_display_name_mappings():
    return {
        "GroupExecutorTrigger": "ç»„æ‰§è¡Œè§¦å‘å™¨ (Group Executor Trigger)"
    }

# æ ‡å‡†å¯¼å‡ºå˜é‡
NODE_CLASS_MAPPINGS = get_node_class_mappings()
NODE_DISPLAY_NAME_MAPPINGS = get_node_display_name_mappings()

if __name__ == "__main__":
    print("[GroupExecutorTrigger] âœ… ä¼˜åŒ–ç»„æ‰§è¡Œè§¦å‘å™¨æ¨¡å—æµ‹è¯•åŠ è½½å®Œæˆ")
    print("[GroupExecutorTrigger] ğŸ“‹ èŠ‚ç‚¹ç±»: GroupExecutorTrigger")
    print("[GroupExecutorTrigger] ğŸ·ï¸ æ˜¾ç¤ºåç§°: ä¼˜åŒ–ç»„æ‰§è¡Œè§¦å‘å™¨ v2.0")
    print("[GroupExecutorTrigger] ğŸ”§ åŸºäºComfyUIåŸç”Ÿæœºåˆ¶")
    print("[GroupExecutorTrigger] âœ… æŠ€æœ¯é”™è¯¯å·²ä¿®æ­£")