"""
ç®€åŒ–çš„å›¾åƒç¼“å­˜è·å–èŠ‚ç‚¹ - Image Cache Get
åªè´Ÿè´£è·å–ç¼“å­˜å›¾åƒå¹¶æä¾›é¢„è§ˆå¼€å…³ï¼Œç¼“å­˜æ§åˆ¶ç”± GroupExecutorManager å¤„ç†
"""

import json
import time
import hashlib
import torch
import numpy as np
from PIL import Image
from typing import Dict, Any, List, Optional

try:
    from ..image_cache_manager.image_cache_manager import cache_manager
except ImportError:
    cache_manager = None

import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ImageCacheGet")

# å¯¼å…¥debugé…ç½®
from ..utils.debug_config import should_debug

CATEGORY_TYPE = "danbooru"
COMPONENT_NAME = "image_cache_get"


class ImageCacheGet:
    """
    ç®€åŒ–çš„å›¾åƒç¼“å­˜è·å–èŠ‚ç‚¹

    åŠŸèƒ½ï¼š
    - ä»ç¼“å­˜ç®¡ç†å™¨è·å–ç¼“å­˜çš„å›¾åƒ
    - æä¾›é¢„è§ˆå¼€å…³ï¼ˆshow_previewï¼‰
    - ç¼“å­˜æ§åˆ¶ç”± GroupExecutorManager å¤„ç†
    """

    # ç±»çº§åˆ«çš„ç¼“å­˜ï¼šå­˜å‚¨æ£€æµ‹ç»“æœï¼Œæ‰€æœ‰å®ä¾‹å…±äº«
    _has_manager_cache = None  # Noneè¡¨ç¤ºæœªæ£€æµ‹ï¼ŒTrue/Falseè¡¨ç¤ºæ£€æµ‹ç»“æœ
    _warning_sent_cache = False  # ç±»çº§åˆ«çš„è­¦å‘Šå‘é€æ ‡å¿—

    def __init__(self):
        pass

    @classmethod
    def _check_for_group_executor_manager(cls, prompt: Optional[Dict]) -> bool:
        """
        æ£€æµ‹å·¥ä½œæµä¸­æ˜¯å¦æœ‰GroupExecutorManagerèŠ‚ç‚¹
        ä½¿ç”¨ç±»çº§åˆ«ç¼“å­˜ï¼Œåªåœ¨ç¬¬ä¸€æ¬¡æ‰§è¡Œæ—¶æ£€æµ‹

        Args:
            prompt: å·¥ä½œæµæ•°æ®

        Returns:
            bool: æ˜¯å¦å­˜åœ¨GroupExecutorManagerèŠ‚ç‚¹
        """
        # å¦‚æœå·²ç»ç¼“å­˜äº†æ£€æµ‹ç»“æœï¼Œç›´æ¥è¿”å›
        if cls._has_manager_cache is not None:
            return cls._has_manager_cache

        # ç¬¬ä¸€æ¬¡æ£€æµ‹
        if not prompt:
            cls._has_manager_cache = False
            return False

        try:
            # promptæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å·¥ä½œæµæ•°æ®å­—å…¸
            workflow_data = prompt[0] if isinstance(prompt, list) and len(prompt) > 0 else prompt

            # éå†å·¥ä½œæµä¸­çš„æ‰€æœ‰èŠ‚ç‚¹
            if isinstance(workflow_data, dict):
                for node_id, node_data in workflow_data.items():
                    if isinstance(node_data, dict) and node_data.get("class_type") == "GroupExecutorManager":
                        logger.info(f"[ImageCacheGet] âœ“ æ£€æµ‹åˆ°GroupExecutorManagerèŠ‚ç‚¹ï¼ˆå·²ç¼“å­˜ï¼‰")
                        cls._has_manager_cache = True
                        return True

            logger.warning(f"[ImageCacheGet] âš  æœªæ£€æµ‹åˆ°GroupExecutorManagerèŠ‚ç‚¹ï¼ˆå·²ç¼“å­˜ï¼‰")
            cls._has_manager_cache = False
            return False
        except Exception as e:
            logger.warning(f"[ImageCacheGet] æ£€æµ‹GroupExecutorManagerå¤±è´¥: {str(e)}")
            cls._has_manager_cache = False
            return False

    @classmethod
    def _send_no_manager_warning(cls):
        """å‘é€WebSocketè­¦å‘Šåˆ°å‰ç«¯ï¼ˆç±»çº§åˆ«ï¼Œåªå‘é€ä¸€æ¬¡ï¼‰"""
        if cls._warning_sent_cache:
            return  # é¿å…é‡å¤å‘é€

        try:
            from server import PromptServer
            PromptServer.instance.send_sync("cache-node-no-manager-warning", {
                "node_type": "ImageCacheGet",
                "message": "å›¾åƒç¼“å­˜èŠ‚ç‚¹éœ€è¦é…åˆç»„æ‰§è¡Œç®¡ç†å™¨ä½¿ç”¨ï¼Œè¯·æ·»åŠ ç»„æ‰§è¡Œç®¡ç†å™¨å’Œè§¦å‘å™¨ååˆ·æ–°ç½‘é¡µ\nImage cache nodes require Group Executor Manager. Please add Manager and Trigger, then refresh."
            })
            cls._warning_sent_cache = True
            logger.info(f"[ImageCacheGet] å·²å‘é€WebSocketè­¦å‘Š")
        except ImportError:
            logger.warning("[ImageCacheGet] è­¦å‘Š: ä¸åœ¨ComfyUIç¯å¢ƒä¸­ï¼Œè·³è¿‡WebSocketé€šçŸ¥")
        except Exception as e:
            logger.warning(f"[ImageCacheGet] WebSocketè­¦å‘Šå‘é€å¤±è´¥: {e}")

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "default_image": ("IMAGE", {
                    "tooltip": "å½“ç¼“å­˜æ— æ•ˆæ—¶ä½¿ç”¨çš„é»˜è®¤å›¾åƒ"
                }),
            },
            "optional": {
                "enable_preview": ("BOOLEAN", {
                    "default": True,
                    "label_on": "true",
                    "label_off": "false",
                    "tooltip": "åˆ‡æ¢å›¾åƒé¢„è§ˆæ˜¾ç¤º/éšè—"
                }),
            },
            "hidden": {
                "unique_id": "UNIQUE_ID",
                "prompt": "PROMPT",
                "extra_pnginfo": "EXTRA_PNGINFO"
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("images",)
    FUNCTION = "get_cached_image"
    CATEGORY = CATEGORY_TYPE
    INPUT_IS_LIST = True
    OUTPUT_NODE = True

    @classmethod
    def IS_CHANGED(cls, default_image=None, enable_preview: bool = True, **kwargs) -> str:
        """
        åŸºäºç¼“å­˜çŠ¶æ€ç”Ÿæˆå˜åŒ–æ£€æµ‹å“ˆå¸Œ
        ç¡®ä¿ç¼“å­˜æ›´æ–°æ—¶èŠ‚ç‚¹é‡æ–°æ‰§è¡Œ
        """
        try:
            # âœ… ä¿®å¤ï¼šåŒ…å«ç¼“å­˜ç®¡ç†å™¨çš„çŠ¶æ€
            cache_timestamp = cache_manager.last_save_timestamp if cache_manager else 0
            cache_count = len(cache_manager.cache_data.get("images", [])) if cache_manager else 0
            current_group = cache_manager.current_group_name if cache_manager else None
            hash_input = f"{enable_preview}_{cache_timestamp}_{cache_count}_{current_group}"
        except Exception:
            # å›é€€åˆ°åŸºæœ¬æ£€æµ‹
            hash_input = f"{enable_preview}_{hash(str(default_image))}"

        return hashlib.md5(hash_input.encode()).hexdigest()

    def get_cached_image(self,
                        default_image: List[torch.Tensor],
                        enable_preview: List[bool] = [True],
                        unique_id: str = "unknown",
                        prompt: Optional[Dict] = None,
                        extra_pnginfo: Optional[Dict] = None) -> Dict[str, Any]:
        """
        è·å–å…¨å±€ç¼“å­˜çš„å›¾åƒï¼ˆé…åˆGroupExecutorManagerä½¿ç”¨ï¼‰

        é‡è¦ï¼šæ­¤èŠ‚ç‚¹å¿…é¡»é…åˆGroupExecutorManagerä½¿ç”¨
        - ä»å…¨å±€ç¼“å­˜è·å–æ‰€æœ‰å›¾åƒï¼ˆä¸ä½¿ç”¨é€šé“éš”ç¦»ï¼‰
        - æ‰§è¡Œé¡ºåºç”±GroupExecutorManageræ§åˆ¶

        Args:
            default_image: é»˜è®¤å›¾åƒåˆ—è¡¨
            enable_preview: æ˜¯å¦æ˜¾ç¤ºé¢„è§ˆåˆ—è¡¨
            unique_id: èŠ‚ç‚¹ID
            prompt: å·¥ä½œæµæ•°æ®
            extra_pnginfo: é¢å¤–ä¿¡æ¯

        Returns:
            åŒ…å«å›¾åƒå’Œé¢„è§ˆçš„å­—å…¸
        """
        start_time = time.time()

        try:
            # å‚æ•°æå–
            enable_preview = enable_preview[0] if enable_preview else True

            if should_debug(COMPONENT_NAME):
                logger.info(f"\n{'='*60}")
                logger.info(f"[ImageCacheGet] â° æ‰§è¡Œæ—¶é—´: {time.strftime('%H:%M:%S', time.localtime())}")
                logger.info(f"[ImageCacheGet] ğŸ¯ èŠ‚ç‚¹ID: {unique_id}")
                logger.info(f"[ImageCacheGet] ğŸ“· æ˜¾ç¤ºé¢„è§ˆ: {enable_preview}")
                logger.info(f"[ImageCacheGet] ğŸ” å½“å‰ç»„å: {cache_manager.current_group_name if cache_manager else 'N/A'}")
                logger.info(f"[ImageCacheGet] ğŸ“ ä½¿ç”¨å…¨å±€ç¼“å­˜ï¼ˆä¸éš”ç¦»é€šé“ï¼‰")
                logger.info(f"{'='*60}\n")

            # âœ… æ£€æµ‹å·¥ä½œæµä¸­æ˜¯å¦æœ‰GroupExecutorManagerèŠ‚ç‚¹ï¼ˆä½¿ç”¨ç¼“å­˜ï¼Œåªæ£€æµ‹ä¸€æ¬¡ï¼‰
            has_manager = ImageCacheGet._check_for_group_executor_manager(prompt)
            if not has_manager:
                # å‘é€WebSocketäº‹ä»¶åˆ°å‰ç«¯æ˜¾ç¤ºtoastï¼ˆåªå‘é€ä¸€æ¬¡ï¼‰
                ImageCacheGet._send_no_manager_warning()

            # è·å–ç¼“å­˜çš„å›¾åƒ
            if cache_manager is None:
                logger.warning("[ImageCacheGet] âš ï¸ ç¼“å­˜ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤å›¾åƒ")
                cached_image = default_image[0] if default_image else torch.zeros((1, 64, 64, 3))
            else:
                try:
                    # âœ… å…³é”®ä¿®å¤ï¼šä»å…¨å±€é€šé“è·å–æ‰€æœ‰ç¼“å­˜å›¾åƒ
                    # ä½¿ç”¨channel_name="__global__"ç¡®ä¿ä»ImageCacheSaveä¿å­˜çš„å…¨å±€é€šé“è¯»å–
                    cached_images = cache_manager.get_cached_images(
                        get_latest=True,
                        channel_name="__global__"
                    )
                    if cached_images and len(cached_images) > 0:
                        # âœ… åˆå¹¶æ‰€æœ‰ç¼“å­˜å›¾åƒä¸ºä¸€ä¸ªæ‰¹æ¬¡
                        # cached_imagesæ˜¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ shapeä¸º(1, H, W, C)
                        # éœ€è¦åˆå¹¶æˆ(N, H, W, C)çš„æ‰¹æ¬¡å¼ é‡
                        cached_image = torch.cat(cached_images, dim=0)
                        if should_debug(COMPONENT_NAME):
                            logger.info(f"[ImageCacheGet] âœ… æˆåŠŸè·å–å…¨å±€ç¼“å­˜å›¾åƒ (å…±{len(cached_images)}å¼ ï¼Œæ‰¹æ¬¡shape: {cached_image.shape})")
                    else:
                        if should_debug(COMPONENT_NAME):
                            logger.info(f"[ImageCacheGet] ğŸ“Œ å…¨å±€ç¼“å­˜ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å›¾åƒ")
                        cached_image = default_image[0] if default_image else torch.zeros((1, 64, 64, 3))
                except Exception as e:
                    logger.warning(f"[ImageCacheGet] âš ï¸ ç¼“å­˜è·å–å¤±è´¥: {str(e)}")
                    import traceback
                    logger.warning(traceback.format_exc())
                    cached_image = default_image[0] if default_image else torch.zeros((1, 64, 64, 3))

            # ç¡®ä¿å›¾åƒæ˜¯æ­£ç¡®çš„æ ¼å¼
            if isinstance(cached_image, torch.Tensor):
                result_image = cached_image
            else:
                result_image = default_image[0] if default_image else torch.zeros((1, 64, 64, 3))

            execution_time = time.time() - start_time
            if should_debug(COMPONENT_NAME):
                logger.info(f"[ImageCacheGet] â±ï¸ æ‰§è¡Œè€—æ—¶: {execution_time:.3f}ç§’\n")

            # è¿”å›æ ‡å‡†æ ¼å¼ï¼š(å›¾åƒå¼ é‡,) å’Œ ui æ•°æ®
            # å¦‚æœå¯ç”¨é¢„è§ˆï¼Œä»å…¨å±€ç¼“å­˜é€šé“è·å–å›¾åƒæ–‡ä»¶ä¿¡æ¯
            ui_data = {}
            if enable_preview and cache_manager is not None:
                try:
                    # âœ… å…³é”®ä¿®å¤ï¼šä»å…¨å±€é€šé“è·å–é¢„è§ˆæ•°æ®
                    cache_channel = cache_manager.get_cache_channel(channel_name="__global__")
                    if cache_channel and "images" in cache_channel and cache_channel["images"]:
                        # è¿”å›ç¼“å­˜çš„å›¾åƒæ–‡ä»¶ä¿¡æ¯ç”¨äºé¢„è§ˆ
                        ui_data = {"images": cache_channel["images"]}
                        if should_debug(COMPONENT_NAME):
                            logger.info(f"[ImageCacheGet] âœ… é¢„è§ˆæ•°æ®å·²å‡†å¤‡: {len(cache_channel['images'])}å¼ å›¾åƒ")
                    else:
                        if should_debug(COMPONENT_NAME):
                            logger.info(f"[ImageCacheGet] ğŸ“Œ å…¨å±€ç¼“å­˜æ— å›¾åƒï¼Œä¸æ˜¾ç¤ºé¢„è§ˆ")
                        ui_data = {"images": []}
                except Exception as e:
                    logger.warning(f"[ImageCacheGet] âš ï¸ è·å–é¢„è§ˆæ•°æ®å¤±è´¥: {str(e)}")
                    ui_data = {"images": []}

            return {
                "result": (result_image,),
                "ui": ui_data
            }

        except Exception as e:
            logger.error(f"[ImageCacheGet] âŒ æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

            # è¿”å›é»˜è®¤å›¾åƒ
            default_img = default_image[0] if default_image else torch.zeros((1, 64, 64, 3))
            return {
                "result": (default_img,),
                "ui": {}
            }


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ImageCacheGet": ImageCacheGet,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ImageCacheGet": "å›¾åƒç¼“å­˜è·å– (Image Cache Get)",
}