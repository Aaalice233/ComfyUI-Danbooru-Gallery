"""
å…¨å±€æ‰§è¡Œåè°ƒå™¨ - Global Execution Coordinator
è´Ÿè´£åè°ƒæ‰€æœ‰ç»„æ‰§è¡Œè¯·æ±‚ï¼Œç¡®ä¿å•ä¸€æ‰§è¡Œè¯­ä¹‰å’Œé˜²æ­¢é‡å¤æ‰§è¡Œ
"""

import json
import time
import hashlib
import threading
from typing import Dict, List, Optional, Tuple
from ..utils.logger import get_logger

logger = get_logger(__name__)


class ExecutionHistoryEntry:
    """æ‰§è¡Œå†å²è®°å½•æ¡ç›®"""
    def __init__(self, execution_id: str, config_hash: str, timestamp: float):
        self.execution_id = execution_id
        self.config_hash = config_hash
        self.timestamp = timestamp
        self.status = "pending"  # pending, running, completed, failed, cancelled


class GlobalExecutionCoordinator:
    """
    å…¨å±€æ‰§è¡Œåè°ƒå™¨
    
    èŒè´£ï¼š
    1. ç”Ÿæˆç¨³å®šçš„execution_idï¼ˆåŸºäºé…ç½®å“ˆå¸Œï¼‰
    2. æ£€æµ‹é‡å¤è¯·æ±‚ï¼ˆ5ç§’å†…ç›¸åŒé…ç½®ï¼‰
    3. ç®¡ç†æ‰§è¡Œæƒé™ï¼ˆå…¨å±€äº’æ–¥é”ï¼‰
    4. ç»´æŠ¤æ‰§è¡Œå†å²è®°å½•
    """
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        """å•ä¾‹æ¨¡å¼"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–åè°ƒå™¨"""
        if hasattr(self, '_initialized'):
            return
        
        self._initialized = True
        
        # æ ¸å¿ƒå±æ€§
        self.current_execution_id: Optional[str] = None
        self.execution_lock = threading.Lock()
        
        # æ‰§è¡Œå†å²ï¼ˆç”¨äºå»é‡ï¼‰
        self.execution_history: Dict[str, ExecutionHistoryEntry] = {}
        self.history_lock = threading.Lock()
        
        # é…ç½®ç¼“å­˜
        self.last_config_hash: Optional[str] = None
        self.last_request_time: float = 0
        
        # é™åˆ¶
        self.max_history_entries = 1000
        self.duplicate_detection_window = 5.0  # 5ç§’å†…é‡å¤è¯·æ±‚æ£€æµ‹çª—å£
        
        logger.info("[GlobalExecutionCoordinator] âœ… å…¨å±€æ‰§è¡Œåè°ƒå™¨å·²åˆå§‹åŒ–")
    
    def generate_stable_execution_id(self, config_data: List[Dict]) -> Tuple[str, str]:
        """
        åŸºäºé…ç½®å†…å®¹ç”Ÿæˆç¨³å®šçš„execution_id
        
        Args:
            config_data: ç»„é…ç½®æ•°æ®åˆ—è¡¨
            
        Returns:
            (execution_id, config_hash) å…ƒç»„
        """
        try:
            # åºåˆ—åŒ–é…ç½®ï¼ˆæ’åºé”®ç¡®ä¿ä¸€è‡´æ€§ï¼‰
            config_str = json.dumps(config_data, sort_keys=True, ensure_ascii=False)
            
            # è®¡ç®—SHA256å“ˆå¸Œ
            config_hash = hashlib.sha256(config_str.encode('utf-8')).hexdigest()
            
            # æˆªå–å‰16ä½ä½œä¸ºçŸ­å“ˆå¸Œ
            short_hash = config_hash[:16]
            
            # ç”Ÿæˆexecution_id: exec_hash_{short_hash}_t_{timestamp}
            timestamp = int(time.time() * 1000)  # æ¯«ç§’çº§æ—¶é—´æˆ³
            execution_id = f"exec_hash_{short_hash}_t_{timestamp}"
            
            logger.debug(f"[GlobalExecutionCoordinator] ğŸ“ ç”Ÿæˆexecution_id: {execution_id}")
            logger.debug(f"[GlobalExecutionCoordinator] ğŸ”‘ é…ç½®å“ˆå¸Œ: {config_hash}")
            
            return execution_id, config_hash
            
        except Exception as e:
            logger.error(f"[GlobalExecutionCoordinator] âŒ ç”Ÿæˆexecution_idå¤±è´¥: {e}")
            # å›é€€åˆ°æ—¶é—´æˆ³æ–¹æ¡ˆ
            fallback_id = f"exec_fallback_{int(time.time())}_{id(config_data)}"
            return fallback_id, ""
    
    def is_duplicate_request(self, config_hash: str, execution_id: str) -> Tuple[bool, str]:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºé‡å¤è¯·æ±‚
        
        Args:
            config_hash: é…ç½®å“ˆå¸Œå€¼
            execution_id: æ‰§è¡ŒID
            
        Returns:
            (is_duplicate, reason) å…ƒç»„
        """
        current_time = time.time()
        
        with self.history_lock:
            # æ£€æŸ¥1: æ˜¯å¦æœ‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡
            if self.current_execution_id is not None:
                # æ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€ä¸ªexecution_idï¼ˆç»­ä¼ åœºæ™¯ï¼‰
                if self.current_execution_id == execution_id:
                    logger.debug(f"[GlobalExecutionCoordinator] âœ… ç»­ä¼ æ‰§è¡Œ: {execution_id}")
                    return False, ""
                else:
                    logger.warning(f"[GlobalExecutionCoordinator] ğŸš« æ‹’ç»ï¼šå·²æœ‰æ‰§è¡Œä»»åŠ¡æ­£åœ¨è¿›è¡Œ")
                    logger.warning(f"   å½“å‰æ‰§è¡Œ: {self.current_execution_id}")
                    logger.warning(f"   æ–°è¯·æ±‚: {execution_id}")
                    return True, f"å·²æœ‰æ‰§è¡Œä»»åŠ¡æ­£åœ¨è¿›è¡Œ: {self.current_execution_id}"
            
            # æ£€æŸ¥2: æ—¶é—´çª—å£å†…çš„é‡å¤é…ç½®
            if config_hash == self.last_config_hash:
                time_since_last = current_time - self.last_request_time
                if time_since_last < self.duplicate_detection_window:
                    logger.warning(f"[GlobalExecutionCoordinator] ğŸš« æ‹’ç»ï¼šé‡å¤è¯·æ±‚")
                    logger.warning(f"   é…ç½®å“ˆå¸Œ: {config_hash}")
                    logger.warning(f"   è·ä¸Šæ¬¡è¯·æ±‚: {time_since_last:.2f}ç§’")
                    logger.warning(f"   æ£€æµ‹çª—å£: {self.duplicate_detection_window}ç§’")
                    return True, f"é‡å¤è¯·æ±‚ï¼ˆ{time_since_last:.1f}ç§’å‰åˆšæäº¤ï¼Œè¯·ç­‰å¾…ï¼‰"
            
            # æ£€æŸ¥3: å†å²è®°å½•ä¸­æ˜¯å¦æœ‰runningçŠ¶æ€çš„ç›¸åŒé…ç½®
            for entry in self.execution_history.values():
                if entry.config_hash == config_hash and entry.status == "running":
                    logger.warning(f"[GlobalExecutionCoordinator] ğŸš« æ‹’ç»ï¼šç›¸åŒé…ç½®æ­£åœ¨æ‰§è¡Œ")
                    logger.warning(f"   æ‰§è¡ŒID: {entry.execution_id}")
                    return True, f"ç›¸åŒé…ç½®æ­£åœ¨æ‰§è¡Œ: {entry.execution_id}"
            
            # æ›´æ–°æœ€è¿‘è¯·æ±‚è®°å½•
            self.last_config_hash = config_hash
            self.last_request_time = current_time
            
            logger.info(f"[GlobalExecutionCoordinator] âœ… é€šè¿‡é‡å¤æ£€æµ‹: {execution_id}")
            return False, ""
    
    def acquire_execution_permission(self, execution_id: str, config_hash: str) -> bool:
        """
        å°è¯•è·å–æ‰§è¡Œæƒé™
        
        Args:
            execution_id: æ‰§è¡ŒID
            config_hash: é…ç½®å“ˆå¸Œ
            
        Returns:
            æ˜¯å¦æˆåŠŸè·å–æƒé™
        """
        with self.execution_lock:
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ‰§è¡Œä»»åŠ¡
            if self.current_execution_id is not None and self.current_execution_id != execution_id:
                logger.warning(f"[GlobalExecutionCoordinator] ğŸ”’ è·å–æƒé™å¤±è´¥ï¼šé”å·²è¢«å ç”¨")
                logger.warning(f"   å½“å‰æŒæœ‰è€…: {self.current_execution_id}")
                logger.warning(f"   è¯·æ±‚è€…: {execution_id}")
                return False
            
            # è·å–æƒé™
            self.current_execution_id = execution_id
            
            # è®°å½•åˆ°å†å²
            with self.history_lock:
                self.execution_history[execution_id] = ExecutionHistoryEntry(
                    execution_id=execution_id,
                    config_hash=config_hash,
                    timestamp=time.time()
                )
                self.execution_history[execution_id].status = "running"
                
                # æ¸…ç†è¿‡æœŸå†å²è®°å½•
                self._cleanup_history()
            
            logger.info(f"[GlobalExecutionCoordinator] ğŸ”“ è·å–æ‰§è¡Œæƒé™æˆåŠŸ: {execution_id}")
            return True
    
    def release_execution_permission(self, execution_id: str, status: str = "completed"):
        """
        é‡Šæ”¾æ‰§è¡Œæƒé™
        
        Args:
            execution_id: æ‰§è¡ŒID
            status: æœ€ç»ˆçŠ¶æ€ï¼ˆcompleted, failed, cancelledï¼‰
        """
        with self.execution_lock:
            if self.current_execution_id == execution_id:
                self.current_execution_id = None
                logger.info(f"[GlobalExecutionCoordinator] ğŸ”“ é‡Šæ”¾æ‰§è¡Œæƒé™: {execution_id} (çŠ¶æ€: {status})")
            else:
                logger.warning(f"[GlobalExecutionCoordinator] âš ï¸ é‡Šæ”¾æƒé™å¤±è´¥ï¼šexecution_idä¸åŒ¹é…")
                logger.warning(f"   å½“å‰æŒæœ‰è€…: {self.current_execution_id}")
                logger.warning(f"   è¯·æ±‚é‡Šæ”¾: {execution_id}")
        
        # æ›´æ–°å†å²çŠ¶æ€
        with self.history_lock:
            if execution_id in self.execution_history:
                self.execution_history[execution_id].status = status
    
    def cancel_all_pending(self):
        """å–æ¶ˆæ‰€æœ‰å¾…å¤„ç†çš„è¯·æ±‚"""
        with self.history_lock:
            cancelled_count = 0
            for entry in self.execution_history.values():
                if entry.status == "pending":
                    entry.status = "cancelled"
                    cancelled_count += 1
            
            if cancelled_count > 0:
                logger.info(f"[GlobalExecutionCoordinator] ğŸ›‘ å·²å–æ¶ˆ {cancelled_count} ä¸ªå¾…å¤„ç†è¯·æ±‚")
    
    def get_execution_status(self, execution_id: str) -> Optional[str]:
        """
        è·å–æ‰§è¡ŒçŠ¶æ€
        
        Args:
            execution_id: æ‰§è¡ŒID
            
        Returns:
            çŠ¶æ€å­—ç¬¦ä¸²æˆ–None
        """
        with self.history_lock:
            entry = self.execution_history.get(execution_id)
            return entry.status if entry else None
    
    def _cleanup_history(self):
        """æ¸…ç†è¿‡æœŸçš„å†å²è®°å½•ï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œéœ€è¦æŒæœ‰history_lockï¼‰"""
        if len(self.execution_history) <= self.max_history_entries:
            return
        
        # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œä¿ç•™æœ€æ–°çš„è®°å½•
        sorted_entries = sorted(
            self.execution_history.items(),
            key=lambda x: x[1].timestamp,
            reverse=True
        )
        
        # ä¿ç•™æœ€æ–°çš„max_history_entriesæ¡è®°å½•
        self.execution_history = dict(sorted_entries[:self.max_history_entries])
        
        logger.debug(f"[GlobalExecutionCoordinator] ğŸ§¹ æ¸…ç†å†å²è®°å½•ï¼Œä¿ç•™ {self.max_history_entries} æ¡")
    
    def force_release_all(self):
        """å¼ºåˆ¶é‡Šæ”¾æ‰€æœ‰é”ï¼ˆç”¨äºç´§æ€¥æ¢å¤ï¼‰"""
        with self.execution_lock:
            if self.current_execution_id:
                logger.warning(f"[GlobalExecutionCoordinator] âš ï¸ å¼ºåˆ¶é‡Šæ”¾é”: {self.current_execution_id}")
                self.current_execution_id = None
        
        with self.history_lock:
            for entry in self.execution_history.values():
                if entry.status == "running":
                    entry.status = "cancelled"
        
        logger.warning("[GlobalExecutionCoordinator] ğŸ›‘ å¼ºåˆ¶é‡Šæ”¾æ‰€æœ‰é”å®Œæˆ")
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self.history_lock:
            total = len(self.execution_history)
            status_counts = {}
            
            for entry in self.execution_history.values():
                status = entry.status
                status_counts[status] = status_counts.get(status, 0) + 1
            
            return {
                "total_executions": total,
                "current_execution": self.current_execution_id,
                "status_counts": status_counts,
                "last_config_hash": self.last_config_hash,
                "last_request_time": self.last_request_time
            }


# å…¨å±€å•ä¾‹å®ä¾‹
_global_coordinator = GlobalExecutionCoordinator()


def get_coordinator() -> GlobalExecutionCoordinator:
    """è·å–å…¨å±€åè°ƒå™¨å®ä¾‹"""
    return _global_coordinator
