"""
ç»„æ‰§è¡Œç®¡ç†å™¨ - ComfyUIèŠ‚ç‚¹
åŸºäºå®˜æ–¹æ–‡æ¡£çš„æ ‡å‡†æ ¼å¼å®ç°
"""

import json
import time
import uuid
import hashlib
import gc
import os
from typing import Dict, Any, List

# å¯¼å…¥æ—¥å¿—ç³»ç»Ÿ
from ..utils.logger import get_logger

# å¯¼å…¥å…¨å±€æ‰§è¡Œåè°ƒå™¨
from .execution_coordinator import get_coordinator

# åˆå§‹åŒ–logger
logger = get_logger(__name__)

# å¯¼å…¥å†…å­˜æ¸…ç†ç›¸å…³æ¨¡å—
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    logger.warning("torchä¸å¯ç”¨ï¼Œæ˜¾å­˜æ¸…ç†åŠŸèƒ½å°†è¢«ç¦ç”¨")

# å¯¼å…¥å†…å­˜ä¿¡æ¯è·å–æ¨¡å—
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    logger.warning("psutilä¸å¯ç”¨ï¼Œç³»ç»Ÿå†…å­˜ä¿¡æ¯åŠŸèƒ½å°†è¢«ç¦ç”¨")

try:
    import comfy.model_management as mm
    COMFY_MM_AVAILABLE = True
except ImportError:
    COMFY_MM_AVAILABLE = False
    logger.warning("comfy.model_managementä¸å¯ç”¨ï¼Œæ¿€è¿›æ¨¡å¼æ¸…ç†å°†è¢«ç¦ç”¨")

# å¯¼å…¥é‡‡æ ·å™¨è¯†åˆ«åŠŸèƒ½ï¼ˆå·²ä» metadata_collector è¿ç§»åˆ° utils.configï¼‰
try:
    from ..utils.config import is_sampler_node
    SAMPLER_CHECK_AVAILABLE = True
except ImportError:
    SAMPLER_CHECK_AVAILABLE = False
    logger.warning("utils.configä¸å¯ç”¨ï¼Œé‡‡æ ·å™¨ç»„æ£€æµ‹å°†è¢«ç¦ç”¨")

    # æä¾›ä¸€ä¸ªfallbackå®ç°
    def is_sampler_node(class_type):
        """Fallback: ç®€å•çš„é‡‡æ ·å™¨èŠ‚ç‚¹åˆ¤æ–­"""
        return "sampler" in class_type.lower() or "ksampler" in class_type.lower()


class AnyType(str):
    """ç”¨äºè¡¨ç¤ºä»»æ„ç±»å‹çš„ç‰¹æ®Šç±»ï¼Œåœ¨ç±»å‹æ¯”è¾ƒæ—¶æ€»æ˜¯è¿”å›Falseï¼ˆä¸ç›¸ç­‰ï¼‰"""
    def __ne__(self, __value: object) -> bool:
        return False


any_typ = AnyType("*")


# âœ… å…¨å±€é…ç½®å­˜å‚¨ï¼ˆå‰åç«¯äº¤äº’çš„æ¢çº½ï¼‰
_group_executor_config = {
    "groups": [],
    "last_update": 0,
    "last_workflow_groups": []  # è¿½è¸ªå·¥ä½œæµä¸­çš„groups
}

def get_group_config():
    """è·å–å½“å‰ä¿å­˜çš„ç»„é…ç½®"""
    return _group_executor_config.get("groups", [])

def set_group_config(groups):
    """ä¿å­˜ç»„é…ç½®"""
    global _group_executor_config
    _group_executor_config["groups"] = groups
    _group_executor_config["last_update"] = time.time()
    logger.info(f"\n[GroupExecutorManager] âœ… é…ç½®å·²æ›´æ–°: {len(groups)} ä¸ªç»„")
    for i, group in enumerate(groups, 1):
        logger.debug(f"   {i}. {group.get('group_name', 'æœªå‘½å')}")


class GroupExecutorManager:
    """Basic Group Executor Manager"""

    @classmethod
    def INPUT_TYPES(cls):
        """å®šä¹‰è¾“å…¥å‚æ•°ç±»å‹ - çº¯è‡ªå®šä¹‰UIç‰ˆæœ¬"""
        return {
            "required": {},
            "optional": {},
            "hidden": {
                "unique_id": "UNIQUE_ID"
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("execution_data",)
    FUNCTION = "create_execution_plan"
    CATEGORY = "danbooru"
    DESCRIPTION = "ç»„æ‰§è¡Œç®¡ç†å™¨ï¼Œç”¨äºç®¡ç†å’Œæ§åˆ¶èŠ‚ç‚¹ç»„çš„æ‰§è¡Œé¡ºåºå’Œç¼“å­˜ç­–ç•¥"
    OUTPUT_IS_LIST = (False,)
    OUTPUT_NODE = True

    @classmethod
    def VALIDATE_INPUTS(cls, input_types):
        """è·³è¿‡wildcardç±»å‹çš„åç«¯éªŒè¯"""
        return True

    @classmethod
    def IS_CHANGED(cls, **kwargs) -> str:
        """
        åŸºäºé…ç½®å†…å®¹æ£€æµ‹ - åªæœ‰é…ç½®æ”¹å˜æ—¶æ‰é‡æ–°æ‰§è¡Œ

        å…³é”®ä¿®å¤ï¼š
        1. ä½¿ç”¨é…ç½®å†…å®¹çš„å“ˆå¸Œè€Œéæ—¶é—´æˆ³ï¼Œé¿å…æ¸…ç©ºä¾èµ–èŠ‚ç‚¹ï¼ˆå¦‚checkpointåŠ è½½å™¨ï¼‰çš„ç¼“å­˜
        2. åªæœ‰å½“ç”¨æˆ·ä¿®æ”¹ç»„é…ç½®æ—¶ï¼ŒIS_CHANGEDæ‰è¿”å›ä¸åŒçš„å€¼
        3. è¿™æ ·å¯ä»¥ä¿æŒcheckpointåŠ è½½å™¨ç­‰èŠ‚ç‚¹çš„ç¼“å­˜ï¼Œé¿å…æ¯æ¬¡æ‰§è¡Œéƒ½é‡æ–°åŠ è½½æ¨¡å‹ï¼ˆ8ç§’ï¼‰
        """
        # è·å–å½“å‰é…ç½®
        config_data = get_group_config()

        # åŸºäºé…ç½®å†…å®¹ç”Ÿæˆå“ˆå¸Œ
        # å°†é…ç½®åºåˆ—åŒ–ä¸ºç¨³å®šçš„å­—ç¬¦ä¸²ï¼ˆsortedç¡®ä¿é¡ºåºä¸€è‡´ï¼‰
        config_str = json.dumps(config_data, sort_keys=True, ensure_ascii=False)
        config_hash = hashlib.md5(config_str.encode()).hexdigest()

        return config_hash

    def create_execution_plan(self, unique_id=None):
        """
        åˆ›å»ºæ‰§è¡Œè®¡åˆ’

        Args:
            unique_id: èŠ‚ç‚¹çš„å”¯ä¸€ID

        Returns:
            tuple: (execution_data,) - åŒ…å«æ‰§è¡Œè®¡åˆ’å’Œç¼“å­˜æ§åˆ¶ä¿¡å·çš„JSONå­—ç¬¦ä¸²
        """
        try:
            logger.debug(f"\n{'='*80}")
            logger.debug(f"ğŸ¯ create_execution_plan è¢«è°ƒç”¨")
            logger.debug(f"{'='*80}")
            logger.debug(f"\n[GroupExecutorManager] ğŸ¯ å¼€å§‹ç”Ÿæˆæ‰§è¡Œè®¡åˆ’")
            logger.debug(f"ğŸ“ èŠ‚ç‚¹ID: {unique_id}")

            # âœ… ä»å…¨å±€é…ç½®ä¸­è¯»å–é…ç½®
            config_data = get_group_config()
            logger.debug(f"[GroupExecutorManager] ğŸ“¦ ä»å…¨å±€é…ç½®è¯»å–: {len(config_data)} ä¸ªç»„")

            # ğŸ” DEBUG: è¯¦ç»†è¾“å‡ºæ¯ä¸ªç»„çš„é…ç½®
            for i, group in enumerate(config_data, 1):
                logger.debug(f"ğŸ“¦ ç»„ {i}: {group.get('group_name', 'æœªå‘½å')}")
                cleanup_cfg = group.get('cleanup_config')
                if cleanup_cfg:
                    logger.debug(f"  - clear_vram: {cleanup_cfg.get('clear_vram')}")
                    logger.debug(f"  - clear_ram: {cleanup_cfg.get('clear_ram')}")
                    logger.debug(f"  - aggressive_mode: {cleanup_cfg.get('aggressive_mode')}")
                    logger.debug(f"  - delay_seconds: {cleanup_cfg.get('delay_seconds')}")

            # âœ… æ–°å¢ï¼šæ£€æµ‹é…ç½®æ˜¯å¦ä¸ºç©ºï¼Œå¦‚æœä¸ºç©ºåˆ™è¿”å›ç¦ç”¨çŠ¶æ€
            if not config_data or len(config_data) == 0:
                logger.warning(f"âš ï¸  é…ç½®ä¸ºç©ºï¼Œè¿”å›ç¦ç”¨çŠ¶æ€")
                disabled_data = {
                    "execution_plan": {
                        "disabled": True,
                        "disabled_reason": "empty_groups",
                        "message": "ç»„æ‰§è¡Œç®¡ç†å™¨é…ç½®ä¸ºç©ºï¼Œå·²è‡ªåŠ¨ç¦ç”¨",
                        "groups": [],
                        "execution_id": f"disabled_{int(time.time())}_{uuid.uuid4().hex[:8]}",
                        "execution_mode": "sequential",
                        "cache_control_mode": "conditional",
                        "client_id": None,
                        "cache_enabled": False,
                        "debug_mode": False
                    },
                    "cache_control_signal": {
                        "execution_id": f"disabled_{int(time.time())}_{uuid.uuid4().hex[:8]}",
                        "enabled": False,
                        "timestamp": time.time(),
                        "enable_cache": False,
                        "cache_key": "disabled",
                        "clear_cache": False,
                        "cache_control_mode": "conditional",
                        "disabled": True,
                        "disabled_reason": "empty_groups"
                    }
                }
                logger.info(f"ğŸš« å·²ç¦ç”¨ç»„æ‰§è¡ŒåŠŸèƒ½ï¼ˆåŸå› ï¼šé…ç½®ä¸ºç©ºï¼‰\n")
                return (json.dumps(disabled_data, ensure_ascii=False),)

            # âœ… æœ‰æœ‰æ•ˆé…ç½®ï¼Œç»§ç»­ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
            logger.info(f"âœ… ä½¿ç”¨ç”¨æˆ·é…ç½®çš„ç»„")

            # å›ºå®šé…ç½®å€¼ï¼ˆå†…éƒ¨ä½¿ç”¨ï¼‰
            execution_mode = "sequential"  # é¡ºåºæ‰§è¡Œ: sequential, å¹¶è¡Œæ‰§è¡Œ: parallel
            cache_control_mode = "conditional"  # æ¡ä»¶ç¼“å­˜: conditional, æ€»æ˜¯å…è®¸: always_allow, ç­‰å¾…è®¸å¯: block_until_allowed
            enable_cache = True
            debug_mode = False

            # âœ… ä½¿ç”¨GlobalExecutionCoordinatorç”Ÿæˆç¨³å®šçš„execution_id
            coordinator = get_coordinator()
            execution_id, config_hash = coordinator.generate_stable_execution_id(config_data)
            logger.info(f"âœ… ç”Ÿæˆç¨³å®šexecution_id: {execution_id}")
            logger.info(f"âœ… é…ç½®å“ˆå¸Œ: {config_hash[:16]}...")
            
            # âœ… æ£€æµ‹é‡å¤è¯·æ±‚
            is_duplicate, reason = coordinator.is_duplicate_request(config_hash, execution_id)
            if is_duplicate:
                logger.warning(f"ğŸš« æ£€æµ‹åˆ°é‡å¤è¯·æ±‚ï¼Œæ‹’ç»æ‰§è¡Œ")
                logger.warning(f"   åŸå› : {reason}")
                
                # è¿”å›æ‹’ç»æ‰§è¡Œçš„å“åº”
                rejected_data = {
                    "execution_plan": {
                        "disabled": True,
                        "disabled_reason": "duplicate_request",
                        "message": f"é‡å¤è¯·æ±‚å·²è¢«æ‹’ç»: {reason}",
                        "groups": [],
                        "execution_id": execution_id,
                        "execution_mode": "sequential",
                        "cache_control_mode": "conditional",
                        "client_id": None,
                        "cache_enabled": False,
                        "debug_mode": False
                    },
                    "cache_control_signal": {
                        "execution_id": execution_id,
                        "enabled": False,
                        "timestamp": time.time(),
                        "enable_cache": False,
                        "cache_key": "rejected",
                        "clear_cache": False,
                        "cache_control_mode": "conditional",
                        "disabled": True,
                        "disabled_reason": "duplicate_request"
                    }
                }
                return (json.dumps(rejected_data, ensure_ascii=False),)
            
            # âœ… å°è¯•è·å–æ‰§è¡Œæƒé™
            if not coordinator.acquire_execution_permission(execution_id, config_hash):
                logger.warning(f"ğŸš« æ— æ³•è·å–æ‰§è¡Œæƒé™")
                
                # è¿”å›æ— æƒé™çš„å“åº”
                no_permission_data = {
                    "execution_plan": {
                        "disabled": True,
                        "disabled_reason": "no_permission",
                        "message": "æ— æ³•è·å–æ‰§è¡Œæƒé™ï¼Œå¯èƒ½æœ‰å…¶ä»–æ‰§è¡Œæ­£åœ¨è¿›è¡Œ",
                        "groups": [],
                        "execution_id": execution_id,
                        "execution_mode": "sequential",
                        "cache_control_mode": "conditional",
                        "client_id": None,
                        "cache_enabled": False,
                        "debug_mode": False
                    },
                    "cache_control_signal": {
                        "execution_id": execution_id,
                        "enabled": False,
                        "timestamp": time.time(),
                        "enable_cache": False,
                        "cache_key": "no_permission",
                        "clear_cache": False,
                        "cache_control_mode": "conditional",
                        "disabled": True,
                        "disabled_reason": "no_permission"
                    }
                }
                return (json.dumps(no_permission_data, ensure_ascii=False),)

            # åˆ›å»ºæ‰§è¡Œè®¡åˆ’ - åŒ…å«éªŒè¯å™¨éœ€è¦çš„æ‰€æœ‰å­—æ®µ
            execution_plan = {
                "groups": config_data,
                "execution_mode": execution_mode,  # âœ… ä¿®å¤ï¼šæ”¹ä¸º execution_mode
                "cache_control_mode": cache_control_mode,  # âœ… ä¿®å¤ï¼šæ·»åŠ  cache_control_mode
                "execution_id": execution_id,  # âœ… ä¿®å¤ï¼šç”Ÿæˆå”¯ä¸€ID
                "client_id": None,  # âœ… ä¿®å¤ï¼šç”±GroupExecutorTriggeråç«¯å¡«å……çœŸå®å€¼
                "cache_enabled": enable_cache,
                "debug_mode": debug_mode
            }

            # åˆ›å»ºç¼“å­˜æ§åˆ¶ä¿¡å·
            cache_signal = {
                "execution_id": execution_id,  # âœ… æ·»åŠ execution_idç”¨äºåŒ¹é…éªŒè¯
                "enabled": True,  # âœ… æƒé™æ£€æŸ¥éœ€è¦æ­¤å­—æ®µï¼Œè¡¨ç¤ºå…è®¸æ‰§è¡Œ
                "timestamp": time.time(),  # âœ… æ·»åŠ æ—¶é—´æˆ³ï¼Œé˜²æ­¢è¶…æ—¶æ£€æŸ¥å¤±è´¥
                "enable_cache": enable_cache,
                "cache_key": f"group_executor_{execution_mode}_{hash(str(config_data))}",
                "clear_cache": not enable_cache,
                "cache_control_mode": cache_control_mode  # âœ… æ·»åŠ ç¼“å­˜æ§åˆ¶æ¨¡å¼
            }

            # ğŸ“‹ è¯¦ç»†è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºç”Ÿæˆçš„æ‰§è¡Œè®¡åˆ’
            logger.debug(f"\n[GroupExecutorManager] ğŸ“‹ ç”Ÿæˆæ‰§è¡Œè®¡åˆ’è¯¦æƒ…:")
            logger.debug(f"   æ‰§è¡ŒID: {execution_id}")
            logger.debug(f"   ç»„æ•°é‡: {len(config_data)}")
            logger.debug(f"   æ‰§è¡Œæ¨¡å¼: {execution_mode}")
            logger.debug(f"   ç¼“å­˜æ¨¡å¼: {cache_control_mode}")
            logger.debug(f"   ")

            for i, group in enumerate(config_data, 1):
                group_name = group.get('group_name', f'æœªå‘½åç»„{i}')
                logger.debug(f"   â”œâ”€ ç»„{i}: {group_name}")

            logger.info(f"\n[GroupExecutorManager] âœ… æ‰§è¡Œè®¡åˆ’ç”Ÿæˆå®Œæˆ\n")

            # âœ… åˆå¹¶ä¸ºå•ä¸ªexecution_dataè¾“å‡º
            execution_data = {
                "execution_plan": execution_plan,
                "cache_control_signal": cache_signal
            }
            execution_data_json = json.dumps(execution_data, ensure_ascii=False)

            # ğŸ“¤ è¾“å‡ºæ—¥å¿—ï¼šæ˜¾ç¤ºå°†è¦å‘é€ç»™GroupExecutorTriggerçš„å†…å®¹
            logger.debug(f"ğŸ“¤ è¾“å‡ºå†…å®¹:")
            logger.debug(f"   â””â”€ execution_data (STRING):")
            logger.debug(f"      {execution_data_json[:200]}...")
            logger.debug(f"")

            return (execution_data_json,)

        except Exception as e:
            error_msg = f"GroupExecutorManager æ‰§è¡Œé”™è¯¯: {str(e)}"
            logger.error(f"\n[GroupExecutorManager] âŒ {error_msg}\n")
            import traceback
            traceback.print_exc()

            # è¿”å›é”™è¯¯ä¿¡æ¯
            error_data = {
                "execution_plan": {"error": error_msg, "execution_id": "error", "groups": []},
                "cache_control_signal": {"clear_cache": True, "error": True}
            }

            return (json.dumps(error_data, ensure_ascii=False),)

# èŠ‚ç‚¹æ˜ å°„ - ç”¨äºComfyUIæ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "GroupExecutorManager": GroupExecutorManager,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "GroupExecutorManager": "ç»„æ‰§è¡Œç®¡ç†å™¨ (Group Executor Manager)",
}

# âœ… æ·»åŠ APIç«¯ç‚¹ - ç”¨äºå‰åç«¯é…ç½®åŒæ­¥
try:
    from server import PromptServer
    from aiohttp import web
    
    routes = PromptServer.instance.routes
    
    # âœ… æ–°å¢ï¼šé‡Šæ”¾æ‰§è¡Œæƒé™çš„APIç«¯ç‚¹
    @routes.post('/danbooru_gallery/group_executor/release_permission')
    async def release_execution_permission(request):
        """é‡Šæ”¾æ‰§è¡Œæƒé™"""
        try:
            data = await request.json()
            execution_id = data.get('execution_id')
            status = data.get('status', 'completed')
            
            if not execution_id:
                return web.json_response({
                    "status": "error",
                    "message": "execution_id is required"
                }, status=400)
            
            # é‡Šæ”¾æ‰§è¡Œæƒé™
            coordinator = get_coordinator()
            coordinator.release_execution_permission(execution_id, status)
            
            logger.info(f"[API] âœ… é‡Šæ”¾æ‰§è¡Œæƒé™: {execution_id} (çŠ¶æ€: {status})")
            
            return web.json_response({
                "status": "success",
                "execution_id": execution_id
            })
        except Exception as e:
            logger.error(f"[API] âŒ é‡Šæ”¾æ‰§è¡Œæƒé™å¤±è´¥: {e}")
            return web.json_response({
                "status": "error",
                "message": str(e)
            }, status=500)
    
    # âœ… æ–°å¢ï¼šç»Ÿè®¡ä¿¡æ¯çš„APIç«¯ç‚¹
    @routes.get('/danbooru_gallery/group_executor/stats')
    async def get_execution_stats(request):
        """è·å–æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
        try:
            coordinator = get_coordinator()
            stats = coordinator.get_stats()
            
            # æ·»åŠ é¢å¤–çš„è¿è¡Œæ—¶ä¿¡æ¯
            import time
            current_execution = None
            if stats.get('current_execution'):
                exec_id = stats['current_execution']
                exec_status = coordinator.get_execution_status(exec_id)
                if exec_status:
                    # è·å–æ‰§è¡Œå†å²ä¿¡æ¯
                    with coordinator.history_lock:
                        entry = coordinator.execution_history.get(exec_id)
                        if entry:
                            current_execution = {
                                "execution_id": exec_id,
                                "status": entry.status,
                                "started_at": time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(entry.timestamp)),
                                "elapsed_seconds": int(time.time() - entry.timestamp)
                            }
            
            result = {
                "status": "success",
                "stats": {
                    "total_executions": stats.get('total_executions', 0),
                    "current_execution_id": stats.get('current_execution'),
                    "status_counts": stats.get('status_counts', {}),
                    "uptime_seconds": int(time.time() - _group_executor_config.get('last_update', time.time()))
                },
                "current_execution": current_execution
            }
            
            logger.debug(f"[API] ğŸ“Š ç»Ÿè®¡ä¿¡æ¯: {result['stats']}")
            
            return web.json_response(result)
        except Exception as e:
            logger.error(f"[API] âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return web.json_response({
                "status": "error",
                "message": str(e)
            }, status=500)
    
    # âœ… æ–°å¢ï¼šå¼ºåˆ¶é‡Šæ”¾æ‰€æœ‰é”çš„APIç«¯ç‚¹
    @routes.post('/danbooru_gallery/group_executor/force_release_all')
    async def force_release_all_locks(request):
        """å¼ºåˆ¶é‡Šæ”¾æ‰€æœ‰é”ï¼ˆç´§æ€¥æ¢å¤ï¼‰"""
        try:
            coordinator = get_coordinator()
            coordinator.force_release_all()
            
            logger.warning(f"[API] âš ï¸ å¼ºåˆ¶é‡Šæ”¾æ‰€æœ‰é”")
            
            return web.json_response({
                "status": "success",
                "message": "å·²å¼ºåˆ¶é‡Šæ”¾æ‰€æœ‰é”"
            })
        except Exception as e:
            logger.error(f"[API] âŒ å¼ºåˆ¶é‡Šæ”¾å¤±è´¥: {e}")
            return web.json_response({
                "status": "error",
                "message": str(e)
            }, status=500)
    
    @routes.post('/danbooru_gallery/group_config/save')
    async def save_group_config(request):
        """ä¿å­˜å‰ç«¯ä¼ å…¥çš„ç»„é…ç½®"""
        try:
            data = await request.json()
            groups = data.get('groups', [])

            logger.debug(f"\n[GroupExecutorManager API] ğŸ” ========== æ”¶åˆ°é…ç½®ä¿å­˜è¯·æ±‚ ==========")
            logger.debug(f"[GroupExecutorManager API] ğŸ“¦ ç»„æ•°é‡: {len(groups)}")

            # ğŸ” DEBUG: è¯¦ç»†è¾“å‡ºæ¯ä¸ªç»„çš„é…ç½®
            for i, group in enumerate(groups, 1):
                logger.debug(f"ğŸ“¦ ç»„ {i}: {group.get('group_name', 'æœªå‘½å')}")
                cleanup_cfg = group.get('cleanup_config')
                if cleanup_cfg:
                    logger.debug(f"  - clear_vram: {cleanup_cfg.get('clear_vram')}")
                    logger.debug(f"  - clear_ram: {cleanup_cfg.get('clear_ram')}")
                    logger.debug(f"  - aggressive_mode: {cleanup_cfg.get('aggressive_mode')}")
                    logger.debug(f"  - delay_seconds: {cleanup_cfg.get('delay_seconds')}")

            # ä¿å­˜åˆ°å…¨å±€é…ç½®
            set_group_config(groups)

            logger.info(f"âœ… é…ç½®å·²ä¿å­˜åˆ°å…¨å±€å­˜å‚¨")
            logger.debug(f"========================================\n")

            return web.json_response({
                "status": "success",
                "message": f"å·²ä¿å­˜ {len(groups)} ä¸ªç»„çš„é…ç½®"
            })
        except Exception as e:
            error_msg = f"[GroupExecutorManager API] âŒ ä¿å­˜é…ç½®é”™è¯¯: {str(e)}"
            logger.debug(error_msg)
            logger.debug(f"========================================\n")
            import traceback
            traceback.print_exc()
            return web.json_response({
                "status": "error",
                "message": str(e)
            }, status=500)
    
    @routes.get('/danbooru_gallery/group_config/load')
    async def load_group_config(request):
        """è·å–å·²ä¿å­˜çš„ç»„é…ç½®"""
        try:
            groups = get_group_config()
            logger.info(f"\n[GroupExecutorManager API] ğŸ“¤ è¿”å›å·²ä¿å­˜çš„é…ç½®: {len(groups)} ä¸ªç»„")
            
            return web.json_response({
                "status": "success",
                "groups": groups,
                "last_update": _group_executor_config.get("last_update", 0)
            })
        except Exception as e:
            error_msg = f"[GroupExecutorManager API] è¯»å–é…ç½®é”™è¯¯: {str(e)}"
            logger.error(error_msg)
            import traceback
            logger.debug(traceback.format_exc())
            return web.json_response({
                "status": "error",
                "message": str(e)
            }, status=500)

    @routes.post('/danbooru_gallery/group_executor/cleanup')
    async def perform_cleanup(request):
        """æ‰§è¡Œå†…å­˜/æ˜¾å­˜æ¸…ç†"""
        try:
            # è¯»å–è¯·æ±‚æ•°æ®
            data = await request.json()

            group_name = data.get('group_name', 'unknown')
            clear_vram = data.get('clear_vram', False)
            clear_ram = data.get('clear_ram', False)
            unload_models = data.get('unload_models', False)
            retry_times = data.get('retry_times', 1)  # âœ… æ–°å¢ï¼šé‡è¯•æ¬¡æ•°é…ç½®ï¼ˆé»˜è®¤1æ¬¡ï¼Œä¸é‡è¯•ï¼‰

            # é™åˆ¶é‡è¯•æ¬¡æ•°èŒƒå›´
            retry_times = max(1, min(retry_times, 5))  # æœ€å°‘1æ¬¡ï¼Œæœ€å¤š5æ¬¡

            # æ£€æŸ¥æ˜¯å¦å®é™…éœ€è¦æ¸…ç†
            if not clear_vram and not clear_ram and not unload_models:
                logger.error(f"â­ï¸ è·³è¿‡æ¸…ç†ï¼ˆç»„: {group_name}ï¼‰ï¼šæ‰€æœ‰é€‰é¡¹å‡å·²ç¦ç”¨")
                return web.json_response({
                    "status": "skipped",
                    "message": "è·³è¿‡æ¸…ç†ï¼šæœªå¯ç”¨ä»»ä½•é€‰é¡¹",
                    "results": {
                        "group_name": group_name,
                        "vram_cleaned": False,
                        "ram_cleaned": False,
                        "models_unloaded": False
                    }
                })

            # âœ… è®°å½•å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—æ€»ç”¨æ—¶ï¼‰
            import time
            import asyncio
            start_time = time.time()

            results = {
                "group_name": group_name,
                "vram_cleaned": False,
                "ram_cleaned": False,
                "models_unloaded": False
            }

            # âœ… æ–°å¢ï¼šé‡è¯•æœºåˆ¶
            last_error = None
            for attempt in range(retry_times):
                try:
                    if retry_times > 1:
                        logger.debug(f"[æ¸…ç† API] ğŸ”„ ç¬¬ {attempt + 1}/{retry_times} æ¬¡å°è¯•æ¸…ç†...")

                    # ====== æ­¥éª¤1ï¼šæ‰§è¡Œæ¸…ç† ======
                    # æ‰§è¡ŒVRAMæ¸…ç†å’Œæ¨¡å‹å¸è½½
                    if clear_vram or unload_models:
                        logger.debug(f"ğŸ”§ æ­£åœ¨æ‰§è¡Œæ˜¾å­˜æ¸…ç†...")
                        cleanup_vram(clear_cache=clear_vram, unload_models=unload_models)
                        results["vram_cleaned"] = clear_vram
                        results["models_unloaded"] = unload_models

                    # æ‰§è¡ŒRAMæ¸…ç†
                    # âš ï¸ é‡è¦ï¼šå¦‚æœå¸è½½äº†æ¨¡å‹ï¼Œå³ä½¿æ²¡å‹¾é€‰"æ¸…ç†å†…å­˜"ä¹Ÿè¦æ‰§è¡Œæ¿€è¿›åƒåœ¾å›æ”¶
                    # è¿™æ ·ç¡®ä¿æ¨¡å‹å¯¹è±¡ä»Pythonå†…å­˜ä¸­å®Œå…¨é‡Šæ”¾
                    if clear_ram or unload_models:
                        logger.debug(f"ğŸ”§ æ­£åœ¨æ‰§è¡Œå†…å­˜æ¸…ç†...")
                        # âœ… æ™ºèƒ½å¯ç”¨æ¿€è¿›æ¸…ç†ï¼šå½“åŒæ—¶æ¸…ç†å†…å­˜å’Œå¸è½½æ¨¡å‹æ—¶ï¼Œå¯ç”¨ç³»ç»Ÿçº§æ¸…ç†
                        aggressive_cleanup = clear_ram and unload_models
                        cleanup_ram(aggressive_cleanup=aggressive_cleanup, unload_models=unload_models)
                        # åªæœ‰æ˜ç¡®å‹¾é€‰äº†æ¸…ç†å†…å­˜æ‰æ ‡è®°ä¸ºå·²æ¸…ç†
                        if clear_ram:
                            results["ram_cleaned"] = True

                    # ====== æ­¥éª¤2ï¼šç­‰å¾…æ¸…ç†å®Œå…¨ç»“æŸ ======
                    logger.debug(f"â³ ç­‰å¾…æ¸…ç†å®Œå…¨ç»“æŸ...")
                    wait_for_cleanup_complete(max_wait_seconds=5.0, required_stable_count=3)

                    # âœ… æˆåŠŸå®Œæˆï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    if retry_times > 1:
                        logger.debug(f"[æ¸…ç† API] âœ… ç¬¬ {attempt + 1} æ¬¡å°è¯•æˆåŠŸ")
                    break

                except Exception as e:
                    last_error = e
                    if attempt < retry_times - 1:
                        logger.warning(f"[æ¸…ç† API] âš ï¸ ç¬¬ {attempt + 1} æ¬¡æ¸…ç†å¤±è´¥ï¼Œ1ç§’åé‡è¯•: {e}")
                        await asyncio.sleep(1)
                    else:
                        logger.error(f"[æ¸…ç† API] âŒ æ‰€æœ‰ {retry_times} æ¬¡é‡è¯•å‡å¤±è´¥: {e}")
                        raise

            # ====== æ­¥éª¤3ï¼šå»¶è¿Ÿç­‰å¾…ï¼ˆå®ç°å‰ç«¯é…ç½®ï¼‰ ======
            delay_seconds = data.get('delay_seconds', 0)
            if delay_seconds > 0:
                logger.error(f"â³ å»¶è¿Ÿ {delay_seconds} ç§’ï¼Œç¡®ä¿å®Œå…¨æ¸…ç†...")
                await asyncio.sleep(delay_seconds)
                logger.error(f"âœ… å»¶è¿Ÿç»“æŸï¼Œå¯ä»¥æ‰§è¡Œä¸‹ä¸€ç»„")

            # ====== æ­¥éª¤4ï¼šæ€»ç»“æ¸…ç†ç»“æœ ======
            elapsed_time = time.time() - start_time

            # âœ… ç®€åŒ–çš„æ¸…ç†æ‘˜è¦ï¼ˆåªæ˜¾ç¤ºæ“ä½œåˆ—è¡¨å’Œæ€»ç”¨æ—¶ï¼Œé‡Šæ”¾é‡å·²åœ¨åº•å±‚å‡½æ•°æ˜¾ç¤ºï¼‰
            operations = []
            if results['vram_cleaned']:
                operations.append("æ¸…ç†æ˜¾å­˜ç¼“å­˜")
            if results['ram_cleaned']:
                operations.append("æ¸…ç†å†…å­˜")
            if results['models_unloaded']:
                operations.append("å¸è½½æ¨¡å‹")

            logger.error(f"ğŸ§¹ å†…å­˜æ¸…ç†å®Œæˆ - ç»„: {group_name}")
            logger.error(f"  ğŸ“‹ æ‰§è¡Œæ“ä½œ: {' | '.join(operations) if operations else 'æ— '}")
            logger.error(f"  â±ï¸ æ€»ç”¨æ—¶: {elapsed_time:.2f}s")

            return web.json_response({
                "status": "success",
                "results": results
            })

        except Exception as e:
            error_msg = f"[æ¸…ç† API] âŒ å¼‚å¸¸: {str(e)}"
            logger.error(error_msg)
            logger.debug(f"========================================\n")
            import traceback
            traceback.print_exc()
            return web.json_response({
                "status": "error",
                "message": str(e)
            }, status=500)

except ImportError as e:
    logger.warning(f"æ— æ³•å¯¼å…¥PromptServeræˆ–webæ¨¡å—ï¼ŒAPIç«¯ç‚¹å°†ä¸å¯ç”¨: {e}")


# ==================== å†…å­˜æ˜¾å­˜æ¸…ç†åŠŸèƒ½ ====================

def get_memory_info():
    """
    è·å–å½“å‰å†…å­˜å’Œæ˜¾å­˜ä½¿ç”¨æƒ…å†µ

    Returns:
        dict: åŒ…å«å†…å­˜å’Œæ˜¾å­˜ä¿¡æ¯çš„å­—å…¸
    """
    info = {
        "vram": {},
        "ram": {}
    }

    # è·å–æ˜¾å­˜ä¿¡æ¯
    if TORCH_AVAILABLE and torch.cuda.is_available():
        try:
            # è·å–æ‰€æœ‰GPUçš„ä¿¡æ¯
            for i in range(torch.cuda.device_count()):
                device = f"cuda:{i}"
                allocated = torch.cuda.memory_allocated(i)
                reserved = torch.cuda.memory_reserved(i)
                total = torch.cuda.get_device_properties(i).total_memory

                info["vram"][device] = {
                    "allocated": allocated,
                    "allocated_mb": allocated / (1024 ** 2),
                    "reserved": reserved,
                    "reserved_mb": reserved / (1024 ** 2),
                    "total": total,
                    "total_mb": total / (1024 ** 2),
                    "free_mb": (total - reserved) / (1024 ** 2)
                }
        except Exception as e:
            logger.debug(f"è·å–æ˜¾å­˜ä¿¡æ¯å¤±è´¥: {e}")
            info["vram"]["error"] = str(e)
    else:
        info["vram"]["available"] = False

    # è·å–ç³»ç»Ÿå†…å­˜ä¿¡æ¯
    if PSUTIL_AVAILABLE:
        try:
            # ç³»ç»Ÿæ€»å†…å­˜
            vm = psutil.virtual_memory()
            info["ram"]["system"] = {
                "total": vm.total,
                "total_mb": vm.total / (1024 ** 2),
                "available": vm.available,
                "available_mb": vm.available / (1024 ** 2),
                "used": vm.used,
                "used_mb": vm.used / (1024 ** 2),
                "percent": vm.percent
            }

            # å½“å‰è¿›ç¨‹å†…å­˜
            process = psutil.Process(os.getpid())
            mem_info = process.memory_info()
            info["ram"]["process"] = {
                "rss": mem_info.rss,
                "rss_mb": mem_info.rss / (1024 ** 2),
                "vms": mem_info.vms,
                "vms_mb": mem_info.vms / (1024 ** 2)
            }
        except Exception as e:
            logger.debug(f"è·å–å†…å­˜ä¿¡æ¯å¤±è´¥: {e}")
            info["ram"]["error"] = str(e)
    else:
        info["ram"]["available"] = False

    return info


def format_memory_comparison(before, after, label="å†…å­˜"):
    """
    æ ¼å¼åŒ–å†…å­˜å¯¹æ¯”ä¿¡æ¯

    Args:
        before: æ¸…ç†å‰çš„ä¿¡æ¯
        after: æ¸…ç†åçš„ä¿¡æ¯
        label: æ ‡ç­¾ï¼ˆå†…å­˜/æ˜¾å­˜ï¼‰

    Returns:
        str: æ ¼å¼åŒ–çš„å¯¹æ¯”å­—ç¬¦ä¸²
    """
    lines = []

    if not before or not after:
        return f"{label}: æ— å¯¹æ¯”æ•°æ®"

    # è®¡ç®—å·®å¼‚
    if "mb" in before and "mb" in after:
        before_mb = before["mb"]
        after_mb = after["mb"]
        diff_mb = before_mb - after_mb
        diff_percent = (diff_mb / before_mb * 100) if before_mb > 0 else 0

        lines.append(f"{label}:")
        lines.append(f"  æ¸…ç†å‰: {before_mb:.2f} MB")
        lines.append(f"  æ¸…ç†å: {after_mb:.2f} MB")
        lines.append(f"  é‡Šæ”¾é‡: {diff_mb:.2f} MB ({diff_percent:.1f}%)")

    return "\n".join(lines)


def cleanup_vram(clear_cache=True, unload_models=False):
    """
    æ¸…ç†æ˜¾å­˜ï¼ˆGPU VRAMï¼‰

    Args:
        clear_cache: æ˜¯å¦æ¸…ç†æ˜¾å­˜ç¼“å­˜
        unload_models: æ˜¯å¦å¸è½½æ‰€æœ‰æ¨¡å‹
    """
    if not TORCH_AVAILABLE:
        logger.warning("âš ï¸ è·³è¿‡ï¼štorch æ¨¡å—ä¸å¯ç”¨")
        return

    try:
        if torch.cuda.is_available():
            # âœ… æ–°å¢ï¼šåŒæ­¥ CUDA æ“ä½œï¼ˆç¡®ä¿å¼‚æ­¥æ“ä½œå®Œæˆï¼‰
            logger.debug("[VRAMæ¸…ç†] ğŸ”§ æ‰§è¡Œ torch.cuda.synchronize()")
            torch.cuda.synchronize()
            logger.debug("[VRAMæ¸…ç†] âœ… CUDA æ“ä½œå·²åŒæ­¥")

            # æ”¶é›†æ¸…ç†å‰çš„æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
            initial_memory = torch.cuda.memory_allocated()
            initial_memory_mb = initial_memory / (1024 ** 2)

            # å¸è½½æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if unload_models and COMFY_MM_AVAILABLE:
                logger.debug("[VRAMæ¸…ç†] ğŸ”§ æ‰§è¡Œ mm.unload_all_models()")
                mm.unload_all_models()
                logger.error("[VRAMæ¸…ç†] âœ… æ¨¡å‹å·²å¸è½½")
                logger.debug("[VRAMæ¸…ç†] ğŸ”§ æ‰§è¡Œ mm.soft_empty_cache()")
                mm.soft_empty_cache()
            elif unload_models and not COMFY_MM_AVAILABLE:
                logger.warning("[VRAMæ¸…ç†] âš ï¸ æ¨¡å‹å¸è½½ä¸å¯ç”¨ï¼ˆcomfy.model_management ä¸å¯ç”¨ï¼‰")

            # æ¸…ç†æ˜¾å­˜ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if clear_cache:
                if COMFY_MM_AVAILABLE:
                    logger.debug("[VRAMæ¸…ç†] ğŸ”§ æ‰§è¡Œ mm.soft_empty_cache()")
                    mm.soft_empty_cache()

                logger.debug("[VRAMæ¸…ç†] ğŸ”§ æ‰§è¡Œ torch.cuda.empty_cache()")
                torch.cuda.empty_cache()
                logger.debug("[VRAMæ¸…ç†] ğŸ”§ æ‰§è¡Œ torch.cuda.ipc_collect()")
                torch.cuda.ipc_collect()
                logger.error("[VRAMæ¸…ç†] âœ… æ˜¾å­˜ç¼“å­˜å·²æ¸…ç†")

            # æ”¶é›†æ¸…ç†åçš„æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
            final_memory = torch.cuda.memory_allocated()
            final_memory_mb = final_memory / (1024 ** 2)
            memory_freed = initial_memory - final_memory
            memory_freed_mb = memory_freed / (1024 ** 2)

            # æ‰“å°ç®€æ´çš„ç»Ÿè®¡
            logger.error(f"[VRAMæ¸…ç†] ğŸ“Š æ¸…ç†å®Œæˆ: {initial_memory_mb:.2f} MB â†’ {final_memory_mb:.2f} MB (é‡Šæ”¾ {memory_freed_mb:.2f} MB)")
        else:
            logger.warning("âš ï¸ è·³è¿‡ï¼šCUDA ä¸å¯ç”¨")
    except Exception as e:
        logger.error(f"âŒ æ˜¾å­˜æ¸…ç†å¤±è´¥: {e}")


def cleanup_ram(aggressive_cleanup=False, unload_models=False):
    """
    æ¸…ç†ç³»ç»Ÿå†…å­˜ï¼ˆRAMï¼‰

    Args:
        aggressive_cleanup: æ˜¯å¦å¯ç”¨æ¿€è¿›æ¸…ç†ï¼ˆç³»ç»Ÿçº§æ¸…ç†ï¼‰
        unload_models: æ˜¯å¦å¸è½½äº†æ¨¡å‹ï¼ˆéœ€è¦æ›´æ¿€è¿›çš„åƒåœ¾å›æ”¶ï¼‰
    """
    import os
    import time

    try:
        # æ”¶é›†æ¸…ç†å‰çš„å†…å­˜ä½¿ç”¨æƒ…å†µ
        initial_memory = None
        if PSUTIL_AVAILABLE:
            initial_memory = psutil.virtual_memory().percent
            logger.debug(f"[RAMæ¸…ç†] åˆå§‹å†…å­˜ä½¿ç”¨: {initial_memory:.2f}%")

        # ç¬¬ä¸€é˜¶æ®µï¼šåƒåœ¾å›æ”¶
        # å¦‚æœå¸è½½äº†æ¨¡å‹ï¼Œæ‰§è¡Œæ›´æ¿€è¿›çš„åƒåœ¾å›æ”¶ï¼ˆå¤šè½®å›æ”¶ç¡®ä¿æ¨¡å‹å¯¹è±¡è¢«é‡Šæ”¾ï¼‰
        if unload_models:
            logger.debug("[RAMæ¸…ç†] â™»ï¸  æ‰§è¡Œæ¿€è¿›åƒåœ¾å›æ”¶ï¼ˆå¸è½½æ¨¡å‹åï¼‰...")
            total_collected = 0
            # æ‰§è¡Œ3è½®åƒåœ¾å›æ”¶ï¼Œç¡®ä¿å¾ªç¯å¼•ç”¨çš„æ¨¡å‹å¯¹è±¡è¢«å®Œå…¨é‡Šæ”¾
            for i in range(3):
                collected = gc.collect(generation=2)  # å®Œæ•´çš„åƒåœ¾å›æ”¶
                total_collected += collected
                logger.debug(f"[RAMæ¸…ç†] ç¬¬{i+1}è½®å›æ”¶: {collected} ä¸ªå¯¹è±¡")
            logger.error(f"[RAMæ¸…ç†] âœ… æ¿€è¿›åƒåœ¾å›æ”¶å®Œæˆï¼ˆå…±å›æ”¶ {total_collected} ä¸ªå¯¹è±¡ï¼Œç¡®ä¿æ¨¡å‹ä»å†…å­˜é‡Šæ”¾ï¼‰")
        else:
            logger.debug("[RAMæ¸…ç†] â™»ï¸  æ‰§è¡Œåƒåœ¾å›æ”¶...")
            collected = gc.collect()
            logger.error(f"[RAMæ¸…ç†] âœ… åƒåœ¾å›æ”¶å®Œæˆï¼ˆå›æ”¶äº† {collected} ä¸ªå¯¹è±¡ï¼‰")

        # ç¬¬äºŒé˜¶æ®µï¼šæ¿€è¿›æ¸…ç†çš„ç³»ç»Ÿçº§æ“ä½œ
        if aggressive_cleanup:
            logger.debug("[RAMæ¸…ç†] ğŸš€ æ‰§è¡Œç³»ç»Ÿçº§æ¸…ç†")

            if os.name == 'nt':  # Windows
                try:
                    import ctypes
                    from ctypes import wintypes

                    # âœ… æ­¥éª¤1ï¼šæ¸…ç†ç³»ç»Ÿæ–‡ä»¶ç¼“å­˜ï¼ˆMemory_Cleanup æŠ€æœ¯ï¼‰
                    try:
                        logger.debug("[RAMæ¸…ç†] ğŸ§¹ æ¸…ç†ç³»ç»Ÿæ–‡ä»¶ç¼“å­˜...")
                        ctypes.windll.kernel32.SetSystemFileCacheSize(
                            wintypes.ULONG(-1),  # MinimumFileCacheSize
                            wintypes.ULONG(-1),  # MaximumFileCacheSize
                            wintypes.ULONG(0)    # Flags
                        )
                        logger.debug("[RAMæ¸…ç†] âœ… ç³»ç»Ÿæ–‡ä»¶ç¼“å­˜å·²æ¸…ç†")
                    except Exception as e:
                        logger.warning(f"[RAMæ¸…ç†] âš ï¸ ç³»ç»Ÿæ–‡ä»¶ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")

                    # âœ… æ­¥éª¤2ï¼šæ¸…ç†DLLï¼ˆMemory_Cleanup æŠ€æœ¯ï¼‰
                    try:
                        logger.debug("[RAMæ¸…ç†] ğŸ§¹ æ¸…ç†æœªä½¿ç”¨çš„DLL...")
                        ctypes.windll.kernel32.SetProcessWorkingSetSize(
                            wintypes.HANDLE(-1),  # hProcess (å½“å‰è¿›ç¨‹)
                            wintypes.ULONG(-1),   # dwMinimumWorkingSetSize
                            wintypes.ULONG(-1)    # dwMaximumWorkingSetSize
                        )
                        logger.debug("[RAMæ¸…ç†] âœ… DLLå·²æ¸…ç†")
                    except Exception as e:
                        logger.warning(f"[RAMæ¸…ç†] âš ï¸ DLLæ¸…ç†å¤±è´¥: {e}")

                    # âœ… æ­¥éª¤3ï¼šæ¸…ç†å½“å‰è¿›ç¨‹å·¥ä½œé›†ï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
                    try:
                        logger.debug("[RAMæ¸…ç†] ğŸ§¹ æ¸…ç†è¿›ç¨‹å·¥ä½œé›†...")
                        ctypes.windll.psapi.EmptyWorkingSet(
                            ctypes.windll.kernel32.GetCurrentProcess()
                        )
                        logger.debug("[RAMæ¸…ç†] âœ… å·¥ä½œé›†å·²æ¸…ç†")
                    except Exception as e:
                        logger.warning(f"[RAMæ¸…ç†] âš ï¸ å·¥ä½œé›†æ¸…ç†å¤±è´¥: {e}")

                    logger.error("[RAMæ¸…ç†] ğŸ‰ Windows ç³»ç»Ÿçº§æ¸…ç†å®Œæˆï¼ˆæ–‡ä»¶ç¼“å­˜ + DLL + å·¥ä½œé›†ï¼‰")

                except Exception as e:
                    logger.warning(f"[RAMæ¸…ç†] âš ï¸ Windows ç³»ç»Ÿçº§æ¸…ç†å¤±è´¥: {e}")

            elif os.name == 'posix':  # Linux/Unix
                try:
                    logger.debug("[RAMæ¸…ç†] Linuxç³»ç»Ÿç¼“å­˜æ¸…ç†...")
                    # åŒæ­¥æ–‡ä»¶ç³»ç»Ÿç¼“å†²åŒº
                    os.system('sync')
                    # æ¸…é™¤é¡µç¼“å­˜ã€ç›®å½•é¡¹å’Œinodeï¼ˆéœ€è¦rootæƒé™ï¼‰
                    with open('/proc/sys/vm/drop_caches', 'w') as f:
                        f.write('3')
                    logger.debug("[RAMæ¸…ç†] ç³»ç»Ÿç¼“å­˜å·²æ¸…ç†")
                except PermissionError:
                    logger.warning("[RAMæ¸…ç†] âš ï¸ Linux ç¼“å­˜æ¸…ç†éœ€è¦ root æƒé™")
                except Exception as e:
                    logger.warning(f"[RAMæ¸…ç†] âš ï¸ Linux ç³»ç»Ÿç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
            else:
                logger.debug(f"[RAMæ¸…ç†] âš ï¸ ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: {os.name}")

        # æ”¶é›†æ¸…ç†åçš„å†…å­˜ä½¿ç”¨æƒ…å†µ
        final_memory = None
        if PSUTIL_AVAILABLE:
            final_memory = psutil.virtual_memory().percent
            logger.debug(f"[RAMæ¸…ç†] æœ€ç»ˆå†…å­˜ä½¿ç”¨: {final_memory:.2f}%")

            if initial_memory is not None:
                memory_freed_percent = initial_memory - final_memory
                logger.error(f"[RAMæ¸…ç†] ğŸ“Š æ¸…ç†å®Œæˆ: {initial_memory:.2f}% â†’ {final_memory:.2f}% (é‡Šæ”¾ {memory_freed_percent:.2f}%)")
        else:
            # æ‰“å°å®Œæˆä¿¡æ¯ï¼ˆæ— ç»Ÿè®¡ï¼‰
            mode_text = "æ¿€è¿›æ¸…ç†" if aggressive_cleanup else "æ™®é€šæ¸…ç†"
            logger.error(f"[RAMæ¸…ç†] âœ… æ¸…ç†å®Œæˆï¼ˆ{mode_text}ï¼‰")

    except Exception as e:
        logger.error(f"âŒ å†…å­˜æ¸…ç†å¤±è´¥: {e}")


def wait_for_cleanup_complete(max_wait_seconds=5.0, required_stable_count=3):
    """
    ç­‰å¾…å¹¶éªŒè¯æ¸…ç†å®Œå…¨å®Œæˆï¼ˆå¾ªç¯æ£€æµ‹ç›´åˆ°ç¨³å®šï¼‰

    Args:
        max_wait_seconds: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        required_stable_count: éœ€è¦è¿ç»­ç¨³å®šçš„æ¬¡æ•°

    Returns:
        bool: æ£€æµ‹åˆ°ç¨³å®šçŠ¶æ€è¿”å›Trueï¼Œè¶…æ—¶è¿”å›False
    """
    import time

    logger.debug(f"â³ [ç­‰å¾…éªŒè¯] å¼€å§‹ç­‰å¾…æ¸…ç†å®Œå…¨å®Œæˆ...")

    try:
        stable_count = 0
        last_vram = None
        last_ram = None
        threshold_vram = 1024 * 1024  # 1MB
        threshold_ram = 10 * 1024 * 1024  # 10MB

        start_time = time.time()
        check_interval = 0.2  # æ¯æ¬¡æ£€æµ‹é—´éš”

        while time.time() - start_time < max_wait_seconds:
            # æ”¶é›†å½“å‰å†…å­˜ä¿¡æ¯
            current_vram = 0
            current_ram = 0

            # æ£€æŸ¥æ˜¾å­˜
            if TORCH_AVAILABLE and torch.cuda.is_available():
                current_vram = torch.cuda.memory_allocated()

            # æ£€æŸ¥ç³»ç»Ÿå†…å­˜
            if PSUTIL_AVAILABLE:
                current_ram = psutil.virtual_memory().used

            # å¦‚æœä¸æ˜¯ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼Œæ¯”è¾ƒç¨³å®šæ€§
            if last_vram is not None and last_ram is not None:
                vram_diff = abs(current_vram - last_vram)
                ram_diff = abs(current_ram - last_ram)

                # åˆ¤æ–­æ˜¯å¦ç¨³å®š
                vram_stable = vram_diff < threshold_vram
                ram_stable = ram_diff < threshold_ram

                if vram_stable and ram_stable:
                    stable_count += 1
                    if stable_count >= required_stable_count:
                        logger.debug(f"âœ… [ç­‰å¾…éªŒè¯] å†…å­˜å·²ç¨³å®šï¼ˆè¿ç»­ {stable_count} æ¬¡æ£€æµ‹ç¨³å®šï¼‰")
                        return True
                else:
                    stable_count = 0  # é‡ç½®è®¡æ•°å™¨
                    logger.debug(f"[ç­‰å¾…éªŒè¯] å†…å­˜ä»åœ¨å˜åŒ–ï¼ˆVRAM: {vram_diff/(1024*1024):.2f}MB, RAM: {ram_diff/(1024*1024):.2f}MBï¼‰")

            # ä¿å­˜å½“å‰å€¼ä½œä¸ºä¸‹æ¬¡æ¯”è¾ƒåŸºå‡†
            last_vram = current_vram
            last_ram = current_ram

            time.sleep(check_interval)

        # è¶…æ—¶æœªè¾¾åˆ°ç¨³å®šçŠ¶æ€
        logger.debug(f"âš ï¸ [ç­‰å¾…éªŒè¯] è¶…æ—¶æœªè¾¾åˆ°ç¨³å®šçŠ¶æ€ï¼ˆ{max_wait_seconds}sï¼‰ï¼Œç»§ç»­æ‰§è¡Œ")
        return False

    except Exception as e:
        logger.warning(f"âš ï¸ [ç­‰å¾…éªŒè¯] å¼‚å¸¸: {e}")
        return False  # å‡ºé”™ä¹Ÿå…è®¸ç»§ç»­


def has_next_sampler_group(current_index: int, groups: List[Dict], workflow: Dict) -> bool:
    """
    æ£€æµ‹åç»­æ˜¯å¦æœ‰åŒ…å«é‡‡æ ·å™¨çš„ç»„

    Args:
        current_index: å½“å‰ç»„çš„ç´¢å¼•
        groups: æ‰€æœ‰ç»„çš„åˆ—è¡¨
        workflow: å·¥ä½œæµæ•°æ®

    Returns:
        bool: å¦‚æœåç»­æœ‰é‡‡æ ·å™¨ç»„è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    if not SAMPLER_CHECK_AVAILABLE:
        logger.debug("è·³è¿‡é‡‡æ ·å™¨ç»„æ£€æµ‹ï¼šmetadata_collectorä¸å¯ç”¨")
        return False

    try:
        # éå†åç»­çš„ç»„
        for i in range(current_index + 1, len(groups)):
            group = groups[i]
            group_name = group.get("group_name")

            if not group_name:
                continue

            # è·å–å·¥ä½œæµä¸­è¯¥ç»„çš„æ‰€æœ‰èŠ‚ç‚¹
            if "nodes" not in workflow:
                continue

            for node_id, node_data in workflow["nodes"].items():
                # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åœ¨è¯¥ç»„ä¸­
                if node_data.get("group") != group_name:
                    continue

                # æ£€æŸ¥æ˜¯å¦æ˜¯é‡‡æ ·å™¨èŠ‚ç‚¹
                class_type = node_data.get("class_type", "")
                if is_sampler_node(class_type):
                    logger.debug(f"[æ¡ä»¶è¯„ä¼°] æ£€æµ‹åˆ°åç»­é‡‡æ ·å™¨ç»„: {group_name} (èŠ‚ç‚¹: {node_id}, ç±»å‹: {class_type})")
                    return True

        logger.debug("åç»­æ— é‡‡æ ·å™¨ç»„")
        return False

    except Exception as e:
        logger.error(f"é‡‡æ ·å™¨ç»„æ£€æµ‹å¤±è´¥: {e}")
        return False


async def get_pcp_param_value(node_id: str, param_name: str) -> Any:
    """
    ä»å‚æ•°æ§åˆ¶é¢æ¿è·å–å‚æ•°å€¼

    Args:
        node_id: å‚æ•°èŠ‚ç‚¹ID
        param_name: å‚æ•°åç§°

    Returns:
        å‚æ•°å€¼ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›None
    """
    try:
        import aiohttp
        async with aiohttp.ClientSession() as session:
            url = f"http://127.0.0.1:8188/danbooru_gallery/pcp/get_param_value"
            params = {"node_id": node_id, "param_name": param_name}

            async with session.get(url, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    if data.get("status") == "success":
                        value = data.get("value")
                        logger.debug(f"è·å–PCPå‚æ•°å€¼: {node_id}.{param_name} = {value}")
                        return value

        logger.error(f"è·å–PCPå‚æ•°å€¼å¤±è´¥: {node_id}.{param_name}")
        return None

    except Exception as e:
        logger.debug(f"è·å–PCPå‚æ•°å€¼å¼‚å¸¸: {e}")
        return None


async def evaluate_condition(condition: Dict, current_index: int, groups: List[Dict], workflow: Dict) -> bool:
    """
    è¯„ä¼°å•ä¸ªæ¡ä»¶

    Args:
        condition: æ¡ä»¶é…ç½®å­—å…¸
        current_index: å½“å‰ç»„ç´¢å¼•
        groups: æ‰€æœ‰ç»„åˆ—è¡¨
        workflow: å·¥ä½œæµæ•°æ®

    Returns:
        bool: æ¡ä»¶æ˜¯å¦æ»¡è¶³
    """
    try:
        condition_type = condition.get("type")
        expected_value = condition.get("value")

        if condition_type == "has_next_sampler_group":
            # æ£€æµ‹æ˜¯å¦æœ‰ä¸‹ä¸€ä¸ªé‡‡æ ·å™¨ç»„
            actual_value = has_next_sampler_group(current_index, groups, workflow)
            result = actual_value == expected_value
            logger.debug(f"has_next_sampler_group: {actual_value} == {expected_value} => {result}")
            return result

        elif condition_type == "pcp_param":
            # æ£€æµ‹å‚æ•°æ§åˆ¶é¢æ¿çš„å‚æ•°å€¼
            node_id = condition.get("node_id")
            param_name = condition.get("param_name")

            if not node_id or not param_name:
                logger.debug(f"pcp_paramæ¡ä»¶ç¼ºå°‘node_idæˆ–param_name")
                return False

            actual_value = await get_pcp_param_value(node_id, param_name)
            result = actual_value == expected_value
            logger.debug(f"pcp_param: {node_id}.{param_name} = {actual_value} == {expected_value} => {result}")
            return result

        else:
            logger.debug(f"æœªçŸ¥çš„æ¡ä»¶ç±»å‹: {condition_type}")
            return False

    except Exception as e:
        logger.debug(f"æ¡ä»¶è¯„ä¼°å¼‚å¸¸: {e}")
        return False


async def check_aggressive_conditions(conditions: List[Dict], current_index: int, groups: List[Dict], workflow: Dict) -> bool:
    """
    æ£€æŸ¥æ¿€è¿›æ¨¡å¼æ¡ä»¶ï¼ˆANDé€»è¾‘ï¼‰

    Args:
        conditions: æ¡ä»¶åˆ—è¡¨
        current_index: å½“å‰ç»„ç´¢å¼•
        groups: æ‰€æœ‰ç»„åˆ—è¡¨
        workflow: å·¥ä½œæµæ•°æ®

    Returns:
        bool: æ‰€æœ‰æ¡ä»¶éƒ½æ»¡è¶³è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    if not conditions:
        logger.debug("æ— æ¿€è¿›æ¨¡å¼æ¡ä»¶ï¼Œé»˜è®¤ä¸å¯ç”¨æ¿€è¿›æ¨¡å¼")
        return False

    try:
        logger.debug(f"[æ¡ä»¶è¯„ä¼°] å¼€å§‹è¯„ä¼° {len(conditions)} ä¸ªæ¿€è¿›æ¨¡å¼æ¡ä»¶")

        # è¯„ä¼°æ‰€æœ‰æ¡ä»¶ï¼ˆANDé€»è¾‘ï¼‰
        for i, condition in enumerate(conditions):
            result = await evaluate_condition(condition, current_index, groups, workflow)
            logger.debug(f"[æ¡ä»¶è¯„ä¼°] æ¡ä»¶ {i+1}/{len(conditions)}: {result}")

            if not result:
                logger.error(f"âŒ æ¡ä»¶ {i+1} ä¸æ»¡è¶³ï¼Œæ¿€è¿›æ¨¡å¼ä¸å¯ç”¨")
                return False

        logger.error("âœ… æ‰€æœ‰æ¡ä»¶éƒ½æ»¡è¶³ï¼Œå¯ç”¨æ¿€è¿›æ¨¡å¼")
        return True

    except Exception as e:
        logger.debug(f"æ¡ä»¶æ£€æŸ¥å¼‚å¸¸: {e}")
        return False