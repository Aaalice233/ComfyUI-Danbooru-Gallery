# -*- coding: utf-8 -*-

import os
import json
import folder_paths
from server import PromptServer
from aiohttp import web
import zipfile
import shutil
import io
import time
import uuid
import tempfile
from datetime import datetime

# Loggerå¯¼å…¥
from ..utils.logger import get_logger
logger = get_logger(__name__)

# æ’ä»¶ç›®å½•
PLUGIN_DIR = os.path.dirname(os.path.abspath(__file__))
# The root directory of the custom node (éœ€è¦å‘ä¸Šä¸¤çº§: py/prompt_selector -> py -> ComfyUI-Danbooru-Gallery)
CUSTOM_NODE_DIR = os.path.abspath(os.path.join(PLUGIN_DIR, '..', '..'))
DATA_FILE = os.path.join(PLUGIN_DIR, "data.json")
DEFAULT_DATA_FILE = os.path.join(PLUGIN_DIR, "default.json")
PREVIEW_DIR = os.path.join(PLUGIN_DIR, "preview")

# === æ•°æ®å®‰å…¨å·¥å…·å‡½æ•° ===

def _validate_data(data):
    """
    éªŒè¯æ•°æ®ç»“æ„çš„å®Œæ•´æ€§

    Args:
        data: å¾…éªŒè¯çš„æ•°æ®å­—å…¸

    Raises:
        ValueError: æ•°æ®ç»“æ„ä¸å®Œæ•´æ—¶æŠ›å‡ºå¼‚å¸¸
    """
    if not isinstance(data, dict):
        raise ValueError("æ•°æ®å¿…é¡»æ˜¯å­—å…¸ç±»å‹")

    if "version" not in data:
        raise ValueError("ç¼ºå°‘ version å­—æ®µ")

    if "categories" not in data:
        raise ValueError("ç¼ºå°‘ categories å­—æ®µ")

    if not isinstance(data["categories"], list):
        raise ValueError("categories å¿…é¡»æ˜¯åˆ—è¡¨ç±»å‹")

    if "settings" not in data:
        raise ValueError("ç¼ºå°‘ settings å­—æ®µ")

    return True

def _create_backup(file_path, max_backups=3):
    """
    åˆ›å»ºæ–‡ä»¶å¤‡ä»½ï¼Œä¿ç•™æœ€è¿‘ N ä¸ªç‰ˆæœ¬

    Args:
        file_path: è¦å¤‡ä»½çš„æ–‡ä»¶è·¯å¾„
        max_backups: æœ€å¤šä¿ç•™çš„å¤‡ä»½æ•°é‡
    """
    if not os.path.exists(file_path):
        return

    try:
        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = f"{file_path}.backup_{timestamp}"

        # åˆ›å»ºå¤‡ä»½
        shutil.copy2(file_path, backup_file)
        logger.info(f"âœ“ å·²åˆ›å»ºå¤‡ä»½: {os.path.basename(backup_file)}")

        # æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™æœ€æ–°çš„ max_backups ä¸ªï¼‰
        backup_dir = os.path.dirname(file_path)
        backup_pattern = f"{os.path.basename(file_path)}.backup_"

        backups = []
        for filename in os.listdir(backup_dir):
            if filename.startswith(backup_pattern):
                full_path = os.path.join(backup_dir, filename)
                backups.append((os.path.getmtime(full_path), full_path))

        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        backups.sort(reverse=True)

        # åˆ é™¤å¤šä½™çš„å¤‡ä»½
        for _, old_backup in backups[max_backups:]:
            try:
                os.remove(old_backup)
                logger.info(f"âœ“ å·²æ¸…ç†æ—§å¤‡ä»½: {os.path.basename(old_backup)}")
            except Exception as e:
                logger.warning(f"âš  æ¸…ç†å¤‡ä»½å¤±è´¥ {os.path.basename(old_backup)}: {e}")

    except Exception as e:
        logger.warning(f"âš  åˆ›å»ºå¤‡ä»½å¤±è´¥: {e}")

def _atomic_save_json(file_path, data, create_backup=True):
    """
    åŸå­æ€§ä¿å­˜ JSON æ•°æ®åˆ°æ–‡ä»¶

    ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ + åŸå­é‡å‘½åæœºåˆ¶ï¼Œç¡®ä¿æ•°æ®å†™å…¥çš„åŸå­æ€§ï¼š
    1. å…ˆå†™å…¥åˆ°ä¸´æ—¶æ–‡ä»¶
    2. å¼ºåˆ¶åˆ·æ–°åˆ°ç£ç›˜ï¼ˆfsyncï¼‰
    3. åŸå­é‡å‘½åè¦†ç›–ç›®æ ‡æ–‡ä»¶
    4. å¼‚å¸¸æ—¶è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶

    Args:
        file_path: ç›®æ ‡æ–‡ä»¶è·¯å¾„
        data: è¦ä¿å­˜çš„æ•°æ®ï¼ˆå­—å…¸ï¼‰
        create_backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½

    Raises:
        ValueError: æ•°æ®éªŒè¯å¤±è´¥
        IOError: æ–‡ä»¶å†™å…¥å¤±è´¥
    """
    # 1. éªŒè¯æ•°æ®ç»“æ„
    _validate_data(data)

    # 2. åˆ›å»ºå¤‡ä»½
    if create_backup:
        _create_backup(file_path)

    # 3. å†™å…¥ä¸´æ—¶æ–‡ä»¶
    temp_fd = None
    temp_path = None

    try:
        # åœ¨åŒä¸€ç›®å½•ä¸‹åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼ˆç¡®ä¿åœ¨åŒä¸€æ–‡ä»¶ç³»ç»Ÿä¸Šï¼Œos.replace æ‰èƒ½åŸå­æ“ä½œï¼‰
        temp_fd, temp_path = tempfile.mkstemp(
            dir=os.path.dirname(file_path),
            prefix='.tmp_',
            suffix='.json'
        )

        # ä½¿ç”¨æ–‡ä»¶æè¿°ç¬¦å†™å…¥æ•°æ®
        with os.fdopen(temp_fd, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
            f.flush()
            os.fsync(f.fileno())  # å¼ºåˆ¶åˆ·æ–°åˆ°ç£ç›˜

        temp_fd = None  # æ–‡ä»¶å·²å…³é—­ï¼Œé¿å…é‡å¤å…³é—­

        # 4. åŸå­é‡å‘½åï¼ˆè¦†ç›–æ—§æ–‡ä»¶ï¼‰
        # os.replace åœ¨ Windows å’Œ Unix ä¸Šéƒ½æ˜¯åŸå­æ“ä½œ
        os.replace(temp_path, file_path)

        logger.info(f"âœ“ æ•°æ®å·²å®‰å…¨ä¿å­˜: {os.path.basename(file_path)}")

    except Exception as e:
        logger.error(f"âœ— ä¿å­˜æ•°æ®å¤±è´¥: {e}")
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_fd is not None:
            try:
                os.close(temp_fd)
            except:
                pass
        if temp_path and os.path.exists(temp_path):
            try:
                os.unlink(temp_path)
            except:
                pass
        raise

class PromptSelector:
    """
    æç¤ºè¯é€‰æ‹©å™¨èŠ‚ç‚¹ï¼Œç”¨äºç®¡ç†å’Œé€‰æ‹©æç¤ºè¯ã€‚
    """
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                # è¿™ä¸ªéšè—å­—æ®µç”¨äºä»å‰ç«¯æ¥æ”¶æœ€ç»ˆçš„æç¤ºè¯å­—ç¬¦ä¸²
                "selected_prompts": ("STRING", {"default": "", "widget": "hidden"}),
            },
            "optional": {
                "prefix_prompt": ("STRING", {"forceInput": True}),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("prompt",)
    FUNCTION = "execute"
    CATEGORY = "danbooru"

    def __init__(self):
        # ç¡®ä¿é¢„è§ˆå›¾ç‰‡ç›®å½•å­˜åœ¨
        if not os.path.exists(PREVIEW_DIR):
            os.makedirs(PREVIEW_DIR)

    def execute(self, **kwargs):
        prefix = kwargs.get("prefix_prompt", "")
        # ä»å‰ç«¯è·å–é€‰æ‹©çš„æç¤ºè¯
        selected_prompts_string = kwargs.get("selected_prompts", "")

        # ä» data.json åŠ è½½è®¾ç½®ä»¥è·å–åˆ†éš”ç¬¦
        separator = ", "
        if os.path.exists(DATA_FILE):
            with open(DATA_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                separator = data.get("settings", {}).get("separator", ", ")

        if prefix and selected_prompts_string:
            final_prompt = f"{prefix}{separator}{selected_prompts_string}"
        elif prefix:
            final_prompt = prefix
        else:
            final_prompt = selected_prompts_string

        return (final_prompt,)

# --- API è·¯ç”± ---

@PromptServer.instance.routes.get("/prompt_selector/data")
async def get_data(request):
    if not os.path.exists(DATA_FILE):
        return web.json_response({"error": "Data file not found"}, status=404)
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return web.json_response(data)
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

@PromptServer.instance.routes.get("/prompt_selector/metadata")
async def get_metadata(request):
    """
    è·å–æ•°æ®å…ƒä¿¡æ¯ï¼ˆä¸è¿”å›å®Œæ•´æ•°æ®ï¼Œä»…ç”¨äºæ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°ï¼‰

    è¿”å›æ ¼å¼:
    {
        "last_modified": "2025-01-22T10:30:45.123Z",
        "version": "1.6",
        "categories_count": 5,
        "total_prompts": 120
    }
    """
    if not os.path.exists(DATA_FILE):
        return web.json_response({"error": "Data file not found"}, status=404)
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)

        total_prompts = sum(len(cat.get("prompts", [])) for cat in data.get("categories", []))

        metadata = {
            "last_modified": data.get("last_modified"),
            "version": data.get("version"),
            "categories_count": len(data.get("categories", [])),
            "total_prompts": total_prompts
        }

        return web.json_response(metadata)
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

@PromptServer.instance.routes.post("/prompt_selector/data")
async def save_data(request):
    try:
        new_data = await request.json()

        # è¯»å–æ—§æ•°æ®ç”¨äºæ™ºèƒ½æ—¶é—´æˆ³æ›´æ–°
        old_data = None
        if os.path.exists(DATA_FILE):
            try:
                with open(DATA_FILE, 'r', encoding='utf-8') as f:
                    old_data = json.load(f)
            except Exception as e:
                logger.warning(f"è¯»å–æ—§æ•°æ®å¤±è´¥ï¼Œå°†è·³è¿‡æ—¶é—´æˆ³æ¯”è¾ƒ: {e}")

        # æ™ºèƒ½æ›´æ–°æ—¶é—´æˆ³ï¼ˆæ£€æµ‹å˜æ›´å¹¶åªæ›´æ–°ä¿®æ”¹çš„é¡¹ï¼‰
        updated_data = _update_timestamps(new_data, old_data)

        # ä½¿ç”¨åŸå­ä¿å­˜æœºåˆ¶ï¼Œç¡®ä¿æ•°æ®å®‰å…¨
        _atomic_save_json(DATA_FILE, updated_data, create_backup=True)

        # è¿”å›å®Œæ•´çš„æœ€æ–°æ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰æ›´æ–°åçš„æ—¶é—´æˆ³ï¼‰
        return web.json_response({
            "success": True,
            "data": updated_data
        })
    except ValueError as e:
        # æ•°æ®éªŒè¯å¤±è´¥
        logger.error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
        return web.json_response({"error": f"æ•°æ®éªŒè¯å¤±è´¥: {str(e)}"}, status=400)
    except Exception as e:
        logger.error(f"ä¿å­˜æ•°æ®å¤±è´¥: {e}")
        return web.json_response({"error": str(e)}, status=500)

@PromptServer.instance.routes.get("/prompt_selector/preview/{filename}")
async def get_preview_image(request):
    filename = request.match_info['filename']
    image_path = os.path.join(PREVIEW_DIR, filename)
    
    # å®‰å…¨æ£€æŸ¥ï¼Œé˜²æ­¢è·¯å¾„éå†
    if not os.path.abspath(image_path).startswith(os.path.abspath(PREVIEW_DIR)):
        return web.Response(status=403)
        
    if os.path.exists(image_path):
        return web.FileResponse(image_path)
    return web.Response(status=404)

@PromptServer.instance.routes.post("/prompt_selector/upload_image")
async def upload_image(request):
    post = await request.post()
    image_file = post.get("image")
    alias = post.get("alias", "")

    if not image_file or not image_file.file:
        return web.json_response({"error": "No image file uploaded"}, status=400)

    if not os.path.exists(PREVIEW_DIR):
        os.makedirs(PREVIEW_DIR)

    _, file_extension = os.path.splitext(image_file.filename)
    if not file_extension:
        file_extension = '.png'

    # Sanitize the alias to create a valid filename
    sanitized_alias = "".join(c for c in alias if c.isalnum() or c in (' ', '_')).rstrip()
    if not sanitized_alias:
        sanitized_alias = "untitled"

    # Create a unique filename based on alias and timestamp
    timestamp = int(time.time())
    unique_filename = f"{sanitized_alias}_{timestamp}{file_extension}"
    image_path = os.path.join(PREVIEW_DIR, unique_filename)

    # Ensure the filename is unique
    count = 1
    while os.path.exists(image_path):
        unique_filename = f"{sanitized_alias}_{timestamp}_{count}{file_extension}"
        image_path = os.path.join(PREVIEW_DIR, unique_filename)
        count += 1

    try:
        with open(image_path, 'wb') as f:
            shutil.copyfileobj(image_file.file, f)
        
        return web.json_response({"filename": unique_filename})
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

def _ensure_data_compatibility(data):
    """ç¡®ä¿å¯¼å…¥çš„æ•°æ®ä¸å½“å‰ç‰ˆæœ¬å…¼å®¹ï¼Œè‡ªåŠ¨æ·»åŠ æ—¶é—´æˆ³å­—æ®µ"""
    if "version" not in data:
        data["version"] = "1.6" # å‡è®¾æ˜¯æ—§ç‰ˆæœ¬

    if "settings" not in data:
        data["settings"] = {
            "language": "zh-CN",
            "separator": ", ",
            "save_selection": True
        }

    # æ·»åŠ å…¨å±€ last_modified æ—¶é—´æˆ³
    if "last_modified" not in data:
        data["last_modified"] = datetime.now().isoformat()

    for category in data.get("categories", []):
        # ç§»é™¤æ—§çš„ last_selected å­—æ®µ
        if "last_selected" in category:
            del category["last_selected"]

        # ä¸ºåˆ†ç±»æ·»åŠ  updated_at æ—¶é—´æˆ³
        if "updated_at" not in category:
            category["updated_at"] = datetime.now().isoformat()

        for prompt in category.get("prompts", []):
            if "id" not in prompt or not prompt["id"]:
                prompt["id"] = str(uuid.uuid4())
            if "description" not in prompt:
                prompt["description"] = ""
            if "tags" not in prompt:
                prompt["tags"] = []
            if "favorite" not in prompt:
                prompt["favorite"] = False
            if "image" not in prompt:
                prompt["image"] = ""
            if "created_at" not in prompt:
                prompt["created_at"] = datetime.now().isoformat()
            # ä¸ºæç¤ºè¯æ·»åŠ  updated_at æ—¶é—´æˆ³
            if "updated_at" not in prompt:
                prompt["updated_at"] = prompt.get("created_at", datetime.now().isoformat())
            if "usage_count" not in prompt:
                prompt["usage_count"] = 0
            if "last_used" not in prompt:
                prompt["last_used"] = None
    return data

def _update_timestamps(new_data, old_data=None):
    """
    æ™ºèƒ½æ›´æ–°æ—¶é—´æˆ³ï¼š
    1. æ¯”è¾ƒæ–°æ—§æ•°æ®ï¼Œæ£€æµ‹å“ªäº›æç¤ºè¯è¢«ä¿®æ”¹
    2. ä¸ºæ–°å¢çš„æç¤ºè¯æ·»åŠ  created_at å’Œ updated_at
    3. ä¸ºä¿®æ”¹çš„æç¤ºè¯æ›´æ–° updated_at
    4. æ›´æ–°å…¨å±€ last_modified

    Args:
        new_data: æ–°çš„æ•°æ®ï¼ˆä»å®¢æˆ·ç«¯æ¥æ”¶ï¼‰
        old_data: æ—§çš„æ•°æ®ï¼ˆä»æ–‡ä»¶è¯»å–ï¼‰ï¼Œå¦‚æœä¸º None åˆ™è·³è¿‡æ¯”è¾ƒ

    Returns:
        æ›´æ–°æ—¶é—´æˆ³åçš„ new_data
    """
    now = datetime.now().isoformat()

    # æ›´æ–°å…¨å±€ last_modified
    new_data["last_modified"] = now

    # å¦‚æœæ²¡æœ‰æ—§æ•°æ®ï¼Œç›´æ¥ç¡®ä¿æ‰€æœ‰å­—æ®µå­˜åœ¨
    if old_data is None:
        return _ensure_data_compatibility(new_data)

    # åˆ›å»ºæ—§æ•°æ®çš„å¿«é€ŸæŸ¥æ‰¾æ˜ å°„
    old_categories_map = {cat["name"]: cat for cat in old_data.get("categories", [])}

    for new_category in new_data.get("categories", []):
        cat_name = new_category.get("name")
        old_category = old_categories_map.get(cat_name)

        # å¦‚æœæ˜¯æ–°åˆ†ç±»
        if not old_category:
            new_category["updated_at"] = now
            # æ–°åˆ†ç±»ä¸­çš„æ‰€æœ‰æç¤ºè¯ä¹Ÿæ˜¯æ–°çš„
            for prompt in new_category.get("prompts", []):
                if "created_at" not in prompt:
                    prompt["created_at"] = now
                prompt["updated_at"] = now
            continue

        # æ¯”è¾ƒåˆ†ç±»çº§åˆ«çš„å˜æ›´ï¼ˆå¦‚åˆ†ç±»åç§°ã€è®¾ç½®ç­‰ï¼‰
        category_modified = False
        for key in new_category:
            if key in ("prompts", "updated_at"):
                continue
            if new_category.get(key) != old_category.get(key):
                category_modified = True
                break

        # åˆ›å»ºæ—§æç¤ºè¯çš„å¿«é€ŸæŸ¥æ‰¾æ˜ å°„ï¼ˆä½¿ç”¨ IDï¼‰
        old_prompts_map = {p.get("id"): p for p in old_category.get("prompts", []) if p.get("id")}

        # æ£€æŸ¥æç¤ºè¯å˜æ›´
        for new_prompt in new_category.get("prompts", []):
            prompt_id = new_prompt.get("id")

            # å¦‚æœæç¤ºè¯æ²¡æœ‰ IDï¼Œæ˜¯æ–°æç¤ºè¯
            if not prompt_id:
                new_prompt["id"] = str(uuid.uuid4())
                new_prompt["created_at"] = now
                new_prompt["updated_at"] = now
                category_modified = True
                continue

            old_prompt = old_prompts_map.get(prompt_id)

            # å¦‚æœæ˜¯æ–°æç¤ºè¯ï¼ˆID ä¸åœ¨æ—§æ•°æ®ä¸­ï¼‰
            if not old_prompt:
                if "created_at" not in new_prompt:
                    new_prompt["created_at"] = now
                new_prompt["updated_at"] = now
                category_modified = True
                continue

            # æ¯”è¾ƒæç¤ºè¯å†…å®¹æ˜¯å¦å˜æ›´
            prompt_modified = False
            for key in new_prompt:
                if key in ("updated_at", "last_used", "usage_count"):
                    continue
                if new_prompt.get(key) != old_prompt.get(key):
                    prompt_modified = True
                    category_modified = True
                    break

            # å¦‚æœæç¤ºè¯è¢«ä¿®æ”¹ï¼Œæ›´æ–° updated_at
            if prompt_modified:
                new_prompt["updated_at"] = now
            else:
                # ä¿æŒæ—§çš„æ—¶é—´æˆ³
                new_prompt["updated_at"] = old_prompt.get("updated_at", old_prompt.get("created_at", now))

            # ç¡®ä¿ created_at å­˜åœ¨
            if "created_at" not in new_prompt:
                new_prompt["created_at"] = old_prompt.get("created_at", now)

        # æ›´æ–°åˆ†ç±»çš„ updated_at
        if category_modified:
            new_category["updated_at"] = now
        else:
            new_category["updated_at"] = old_category.get("updated_at", now)

    # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µå­˜åœ¨
    return _ensure_data_compatibility(new_data)

@PromptServer.instance.routes.post("/prompt_selector/pre_import")
async def pre_import_zip(request):
    post = await request.post()
    zip_file = post.get("zip_file")
    if not zip_file or not zip_file.file:
        return web.json_response({"error": "No file uploaded"}, status=400)

    try:
        with zipfile.ZipFile(zip_file.file, 'r') as zf:
            if 'data.json' not in zf.namelist():
                return web.json_response({"error": "ZIP file must contain data.json"}, status=400)
            
            with zf.open('data.json') as f:
                import_data = json.load(f)
            
            categories = [cat.get("name") for cat in import_data.get("categories", [])]
            return web.json_response({"categories": categories})
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

@PromptServer.instance.routes.post("/prompt_selector/import")
async def import_zip(request):
    post = await request.post()
    zip_file = post.get("zip_file")
    selected_categories_str = post.get("selected_categories", "[]")
    
    if not zip_file or not zip_file.file:
        return web.json_response({"error": "No file uploaded"}, status=400)

    try:
        selected_categories = json.loads(selected_categories_str)
        
        # åŠ è½½æœ¬åœ°æ•°æ®
        if os.path.exists(DATA_FILE):
            with open(DATA_FILE, 'r', encoding='utf-8') as f:
                local_data = json.load(f)
        else:
            # å¦‚æœæœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªç©ºçš„ç»“æ„
            local_data = {
                "version": "1.6",
                "categories": [],
                "settings": { "language": "zh-CN", "separator": ", ", "save_selection": True }
            }

        with zipfile.ZipFile(zip_file.file, 'r') as zf:
            if 'data.json' not in zf.namelist():
                return web.json_response({"error": "ZIP file must contain data.json"}, status=400)
            
            with zf.open('data.json') as f:
                import_data = json.load(f)

            compatible_data = _ensure_data_compatibility(import_data)
            
            local_categories = {cat["name"]: cat for cat in local_data["categories"]}
            imported_images = set()

            for category in compatible_data.get("categories", []):
                cat_name = category.get("name")
                if cat_name not in selected_categories:
                    continue

                # å¦‚æœæœ¬åœ°ä¸å­˜åœ¨è¯¥åˆ†ç±»ï¼Œåˆ™ç›´æ¥æ·»åŠ 
                if cat_name not in local_categories:
                    local_data["categories"].append(category)
                    local_categories[cat_name] = category # æ›´æ–°æ˜ å°„
                    # è®°å½•æ‰€æœ‰è¯¥åˆ†ç±»ä¸‹çš„å›¾ç‰‡
                    for prompt in category.get("prompts", []):
                        if prompt.get("image"):
                            imported_images.add(prompt["image"])
                else:
                    # å¦‚æœæœ¬åœ°å­˜åœ¨è¯¥åˆ†ç±»ï¼Œåˆ™åˆå¹¶
                    local_category = local_categories[cat_name]
                    local_prompts = {p.get("alias", p.get("prompt")): p for p in local_category.get("prompts", [])}
                    
                    for prompt in category.get("prompts", []):
                        prompt_key = prompt.get("alias", prompt.get("prompt"))
                        
                        # å¦‚æœæœ¬åœ°å·²å­˜åœ¨åŒåæç¤ºè¯ï¼Œåˆ™æ›´æ–°
                        if prompt_key in local_prompts:
                            # æ›´æ–°é™¤äº† id ä¹‹å¤–çš„æ‰€æœ‰å­—æ®µ
                            existing_prompt = local_prompts[prompt_key]
                            for key, value in prompt.items():
                                if key != "id":
                                    existing_prompt[key] = value
                        else:
                            # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™æ–°å¢
                            local_category.get("prompts", []).append(prompt)
                        
                        # è®°å½•å›¾ç‰‡
                        if prompt.get("image"):
                            imported_images.add(prompt["image"])

            # æå–å¹¶ä¿å­˜ç›¸å…³çš„å›¾ç‰‡
            if not os.path.exists(PREVIEW_DIR):
                os.makedirs(PREVIEW_DIR)
                
            for image_name in imported_images:
                zip_image_path = f'preview/{image_name}'
                if zip_image_path in zf.namelist():
                    target_path = os.path.join(PREVIEW_DIR, image_name)
                    # åªæœ‰å½“æ–‡ä»¶ä¸å­˜åœ¨æ—¶æ‰å†™å…¥ï¼Œé¿å…è¦†ç›–
                    if not os.path.exists(target_path):
                        with zf.open(zip_image_path) as source, open(target_path, 'wb') as target:
                            shutil.copyfileobj(source, target)

            # ä¿å­˜åˆå¹¶åçš„æ•°æ®ï¼ˆä½¿ç”¨åŸå­ä¿å­˜æœºåˆ¶ï¼‰
            _atomic_save_json(DATA_FILE, local_data, create_backup=True)

        return web.json_response({"success": True})
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

@PromptServer.instance.routes.get("/prompt_selector/export")
async def export_zip(request):
    try:
        memory_file = io.BytesIO()
        with zipfile.ZipFile(memory_file, 'w', zipfile.ZIP_DEFLATED) as zf:
            # æ·»åŠ  data.json
            zf.write(DATA_FILE, arcname='data.json')
            # æ·»åŠ å›¾ç‰‡
            if os.path.exists(PREVIEW_DIR):
                for root, _, files in os.walk(PREVIEW_DIR):
                    for file in files:
                        zf.write(os.path.join(root, file), arcname=os.path.join('preview', file))
        
        memory_file.seek(0)
        return web.Response(
            body=memory_file.read(),
            content_type='application/zip',
            headers={'Content-Disposition': 'attachment; filename="prompt_library.zip"'}
        )
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

# --- æ–°å¢çš„ç®¡ç†åŠŸèƒ½API ---

@PromptServer.instance.routes.post("/prompt_selector/category/rename")
async def rename_category(request):
    """é‡å‘½ååˆ†ç±»"""
    try:
        data = await request.json()
        old_name = data.get("old_name")
        new_name = data.get("new_name")
        
        if not old_name or not new_name:
            return web.json_response({"error": "Missing category names"}, status=400)
            
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            file_data = json.load(f)
            
        # æ£€æŸ¥æ–°åç§°æ˜¯å¦å·²å­˜åœ¨
        if any(cat["name"] == new_name for cat in file_data["categories"]):
            return web.json_response({"error": "Category name already exists"}, status=400)
            
        # æŸ¥æ‰¾å¹¶é‡å‘½ååˆ†ç±»
        renamed_category = None
        for category in file_data["categories"]:
            if category["name"] == old_name:
                category["name"] = new_name
                renamed_category = category
                break
        else:
            return web.json_response({"error": "Category not found"}, status=404)

        # æ›´æ–°åˆ†ç±»å’Œå…¨å±€æ—¶é—´æˆ³
        now = datetime.now().isoformat()
        renamed_category["updated_at"] = now
        file_data["last_modified"] = now

        # ä½¿ç”¨åŸå­ä¿å­˜æœºåˆ¶
        _atomic_save_json(DATA_FILE, file_data, create_backup=True)

        return web.json_response({"success": True})
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

@PromptServer.instance.routes.post("/prompt_selector/category/delete")
async def delete_category(request):
    """åˆ é™¤åˆ†ç±»åŠå…¶å­åˆ†ç±»"""
    try:
        data = await request.json()
        category_name_to_delete = data.get("name")

        if not category_name_to_delete:
            return web.json_response({"error": "Missing category name"}, status=400)

        if not os.path.exists(DATA_FILE):
            return web.json_response({"success": True})

        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            file_data = json.load(f)

        prefix_to_delete = category_name_to_delete + '/'
        categories_to_keep = []
        for cat in file_data.get("categories", []):
            original_cat_name = cat.get("name", "")
            # Sanitize the name by removing any leading slashes before comparison
            sanitized_cat_name = original_cat_name.lstrip('/')
            
            keep = sanitized_cat_name != category_name_to_delete and not sanitized_cat_name.startswith(prefix_to_delete)
            if keep:
                categories_to_keep.append(cat)


        file_data["categories"] = categories_to_keep

        if "categories" not in file_data:
            file_data["categories"] = []

        # ä½¿ç”¨åŸå­ä¿å­˜æœºåˆ¶
        _atomic_save_json(DATA_FILE, file_data, create_backup=True)

        return web.json_response({"success": True})
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

@PromptServer.instance.routes.post("/prompt_selector/prompts/batch_delete")
async def batch_delete_prompts(request):
    """æ‰¹é‡åˆ é™¤æç¤ºè¯"""
    try:
        data = await request.json()
        category_name = data.get("category")
        prompt_ids = data.get("prompt_ids", [])
        
        if not category_name or not prompt_ids:
            return web.json_response({"error": "Missing parameters"}, status=400)
            
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            file_data = json.load(f)
            
        # æŸ¥æ‰¾åˆ†ç±»å¹¶åˆ é™¤æŒ‡å®šçš„æç¤ºè¯
        for category in file_data["categories"]:
            if category["name"] == category_name:
                # ä¸ºæç¤ºè¯æ·»åŠ ä¸´æ—¶IDä»¥ä¾¿åˆ é™¤
                for i, prompt in enumerate(category["prompts"]):
                    if not prompt.get("id"):
                        prompt["id"] = str(uuid.uuid4())

                category["prompts"] = [p for p in category["prompts"] if p.get("id") not in prompt_ids]

                # æ›´æ–°åˆ†ç±»å’Œå…¨å±€æ—¶é—´æˆ³ï¼ˆåˆ é™¤æ“ä½œï¼‰
                now = datetime.now().isoformat()
                category["updated_at"] = now
                file_data["last_modified"] = now
                break

        # ä½¿ç”¨åŸå­ä¿å­˜æœºåˆ¶
        _atomic_save_json(DATA_FILE, file_data, create_backup=True)

        return web.json_response({"success": True})
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

@PromptServer.instance.routes.post("/prompt_selector/prompts/batch_move")
async def batch_move_prompts(request):
    """æ‰¹é‡ç§»åŠ¨æç¤ºè¯åˆ°å…¶ä»–åˆ†ç±»"""
    try:
        data = await request.json()
        source_category = data.get("source_category")
        target_category = data.get("target_category")
        prompt_ids = data.get("prompt_ids", [])
        
        if not source_category or not target_category or not prompt_ids:
            return web.json_response({"error": "Missing parameters"}, status=400)
            
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            file_data = json.load(f)
            
        # æŸ¥æ‰¾æºåˆ†ç±»å’Œç›®æ ‡åˆ†ç±»
        source_cat = None
        target_cat = None
        for category in file_data["categories"]:
            if category["name"] == source_category:
                source_cat = category
            elif category["name"] == target_category:
                target_cat = category
                
        if not source_cat or not target_cat:
            return web.json_response({"error": "Category not found"}, status=404)
            
        # ç§»åŠ¨æç¤ºè¯
        prompts_to_move = []
        for prompt in source_cat["prompts"][:]:
            if prompt.get("id") in prompt_ids:
                prompts_to_move.append(prompt)
                source_cat["prompts"].remove(prompt)

        target_cat["prompts"].extend(prompts_to_move)

        # æ›´æ–°æºåˆ†ç±»å’Œç›®æ ‡åˆ†ç±»çš„æ—¶é—´æˆ³
        now = datetime.now().isoformat()
        source_cat["updated_at"] = now
        target_cat["updated_at"] = now
        file_data["last_modified"] = now

        # ä½¿ç”¨åŸå­ä¿å­˜æœºåˆ¶
        _atomic_save_json(DATA_FILE, file_data, create_backup=True)

        return web.json_response({"success": True})
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

@PromptServer.instance.routes.post("/prompt_selector/prompts/update_order")
async def update_prompt_order(request):
    """æ›´æ–°æç¤ºè¯æ’åº"""
    try:
        data = await request.json()
        category_name = data.get("category")
        ordered_ids = data.get("ordered_ids", [])
        
        if not category_name or not ordered_ids:
            return web.json_response({"error": "Missing parameters"}, status=400)
            
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            file_data = json.load(f)
            
        # æŸ¥æ‰¾åˆ†ç±»å¹¶é‡æ–°æ’åº
        for category in file_data["categories"]:
            if category["name"] == category_name:
                # åˆ›å»ºIDåˆ°æç¤ºè¯çš„æ˜ å°„
                prompt_map = {p.get("id"): p for p in category["prompts"]}
                # æŒ‰æ–°é¡ºåºé‡æ–°æ’åˆ—
                category["prompts"] = [prompt_map[pid] for pid in ordered_ids if pid in prompt_map]

                # æ›´æ–°åˆ†ç±»å’Œå…¨å±€æ—¶é—´æˆ³ï¼ˆæ’åºæ“ä½œï¼‰
                now = datetime.now().isoformat()
                category["updated_at"] = now
                file_data["last_modified"] = now
                break

        # ä½¿ç”¨åŸå­ä¿å­˜æœºåˆ¶
        _atomic_save_json(DATA_FILE, file_data, create_backup=True)

        return web.json_response({"success": True})
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

@PromptServer.instance.routes.post("/prompt_selector/prompts/toggle_favorite")
async def toggle_favorite(request):
    """åˆ‡æ¢æç¤ºè¯æ”¶è—çŠ¶æ€"""
    try:
        data = await request.json()
        category_name = data.get("category")
        prompt_id = data.get("prompt_id")
        
        if not category_name or not prompt_id:
            return web.json_response({"error": "Missing parameters"}, status=400)
            
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            file_data = json.load(f)
            
        # æŸ¥æ‰¾æç¤ºè¯å¹¶åˆ‡æ¢æ”¶è—çŠ¶æ€
        for category in file_data["categories"]:
            if category["name"] == category_name:
                for prompt in category["prompts"]:
                    if prompt.get("id") == prompt_id:
                        prompt["favorite"] = not prompt.get("favorite", False)

                        # æ›´æ–°æç¤ºè¯ã€åˆ†ç±»å’Œå…¨å±€æ—¶é—´æˆ³
                        now = datetime.now().isoformat()
                        prompt["updated_at"] = now
                        category["updated_at"] = now
                        file_data["last_modified"] = now
                        break
                break

        # ä½¿ç”¨åŸå­ä¿å­˜æœºåˆ¶
        _atomic_save_json(DATA_FILE, file_data, create_backup=True)

        return web.json_response({"success": True})
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

# ç¡®ä¿åœ¨å¯åŠ¨æ—¶ data.json æ–‡ä»¶å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºä¸€ä¸ªç©ºçš„ç»“æ„
def initialize_data_file():
    # === è¯åº“è‡ªåŠ¨è¿ç§»é€»è¾‘ ===
    # æ£€æµ‹æ—§ç‰ˆæœ¬è¯åº“è·¯å¾„å¹¶è‡ªåŠ¨è¿ç§»åˆ°æ–°ä½ç½®
    OLD_BASE_DIR = os.path.join(CUSTOM_NODE_DIR, "prompt_selector")
    OLD_DATA_FILE = os.path.join(OLD_BASE_DIR, "data.json")
    OLD_PREVIEW_DIR = os.path.join(OLD_BASE_DIR, "preview")
    MIGRATION_MARKER = os.path.join(OLD_BASE_DIR, "MIGRATED.txt")

    # è¿ç§»æ¡ä»¶ï¼šæ—§æ•°æ®å­˜åœ¨ + æœªæ ‡è®°å·²è¿ç§»
    if os.path.exists(OLD_DATA_FILE) and not os.path.exists(MIGRATION_MARKER):
        try:
            logger.error("ğŸ” æ£€æµ‹åˆ°æ—§ç‰ˆæœ¬è¯åº“æ•°æ®ï¼Œå¼€å§‹è‡ªåŠ¨è¿ç§»...")

            # 1. å¤‡ä»½æ—§æ•°æ®
            backup_file = OLD_DATA_FILE + ".backup"
            shutil.copy2(OLD_DATA_FILE, backup_file)
            logger.error(f"ğŸ“¦ å¤‡ä»½å·²åˆ›å»º: {backup_file}")

            # 2. åˆ›å»ºæ–°ç›®å½•ç»“æ„
            os.makedirs(os.path.dirname(DATA_FILE), exist_ok=True)
            os.makedirs(PREVIEW_DIR, exist_ok=True)

            # 3. åŠ è½½æ—§æ•°æ®
            with open(OLD_DATA_FILE, 'r', encoding='utf-8') as f:
                old_data = json.load(f)
            old_data = _ensure_data_compatibility(old_data)

            # 4. åˆå¹¶ç­–ç•¥ï¼šç›¸åŒçš„è¦†ç›–ï¼Œæ²¡æœ‰çš„æ–°å¢
            if os.path.exists(DATA_FILE):
                # æ–°æ•°æ®å­˜åœ¨ï¼Œè¿›è¡Œåˆå¹¶
                logger.error("ğŸ“ æ£€æµ‹åˆ°æ–°æ•°æ®ï¼Œæ‰§è¡Œåˆå¹¶ç­–ç•¥ï¼ˆç›¸åŒè¦†ç›–ï¼Œæ²¡æœ‰æ–°å¢ï¼‰")
                with open(DATA_FILE, 'r', encoding='utf-8') as f:
                    new_data = json.load(f)
                new_data = _ensure_data_compatibility(new_data)

                # åˆå¹¶åˆ†ç±»å’Œæç¤ºè¯
                new_categories_map = {cat["name"]: cat for cat in new_data.get("categories", [])}

                for old_category in old_data.get("categories", []):
                    cat_name = old_category.get("name")

                    if cat_name not in new_categories_map:
                        # åˆ†ç±»ä¸å­˜åœ¨ï¼Œç›´æ¥æ·»åŠ 
                        new_data["categories"].append(old_category)
                        logger.error(f"  âœ“ æ–°å¢åˆ†ç±»: {cat_name}")
                    else:
                        # åˆ†ç±»å­˜åœ¨ï¼Œåˆå¹¶æç¤ºè¯
                        new_category = new_categories_map[cat_name]
                        new_prompts_map = {
                            p.get("alias") or p.get("prompt"): p
                            for p in new_category.get("prompts", [])
                        }

                        for old_prompt in old_category.get("prompts", []):
                            prompt_key = old_prompt.get("alias") or old_prompt.get("prompt")

                            if prompt_key not in new_prompts_map:
                                # æç¤ºè¯ä¸å­˜åœ¨ï¼Œæ·»åŠ 
                                new_category["prompts"].append(old_prompt)
                            else:
                                # æç¤ºè¯å­˜åœ¨ï¼Œè¦†ç›–ï¼ˆä¿ç•™idï¼‰
                                existing_prompt = new_prompts_map[prompt_key]
                                old_id = existing_prompt.get("id")
                                for key, value in old_prompt.items():
                                    existing_prompt[key] = value
                                if old_id:
                                    existing_prompt["id"] = old_id

                # åˆå¹¶è®¾ç½®ï¼ˆæ—§æ•°æ®ä¼˜å…ˆï¼‰
                new_data["settings"].update(old_data.get("settings", {}))
                merged_data = new_data
                logger.error("âœ“ æ•°æ®åˆå¹¶å®Œæˆ")
            else:
                # æ–°æ•°æ®ä¸å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨æ—§æ•°æ®
                merged_data = old_data
                logger.error("âœ“ æ–°æ•°æ®ä¸å­˜åœ¨ï¼Œç›´æ¥è¿ç§»æ—§æ•°æ®")

            # 5. ä¿å­˜åˆå¹¶åçš„æ•°æ®ï¼ˆä½¿ç”¨åŸå­ä¿å­˜æœºåˆ¶ï¼‰
            _atomic_save_json(DATA_FILE, merged_data, create_backup=False)
            logger.error("âœ“ è¯åº“æ•°æ®å·²ä¿å­˜")

            # 6. è¿ç§» preview ç›®å½•
            preview_count = 0
            if os.path.exists(OLD_PREVIEW_DIR):
                for filename in os.listdir(OLD_PREVIEW_DIR):
                    src = os.path.join(OLD_PREVIEW_DIR, filename)
                    dst = os.path.join(PREVIEW_DIR, filename)
                    if os.path.isfile(src):
                        # åªæœ‰å½“ç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨æ—¶æ‰å¤åˆ¶ï¼ˆé¿å…è¦†ç›–æ–°å›¾ç‰‡ï¼‰
                        if not os.path.exists(dst):
                            shutil.copy2(src, dst)
                            preview_count += 1
                logger.error(f"âœ“ é¢„è§ˆå›¾è¿ç§»å®Œæˆ ({preview_count} ä¸ªæ–°æ–‡ä»¶)")

            # 7. åˆ›å»ºè¿ç§»æ ‡è®°æ–‡ä»¶
            with open(MIGRATION_MARKER, 'w', encoding='utf-8') as f:
                f.write(f"è¿ç§»å®Œæˆæ—¶é—´: {datetime.now().isoformat()}\n")
                f.write(f"æ–°æ•°æ®ä½ç½®: {DATA_FILE}\n")
                f.write("æ³¨æ„: æ­¤ç›®å½•ä¸‹çš„æ–‡ä»¶å·²è¿ç§»åˆ°æ–°ä½ç½®ï¼Œå¯ä»¥æ‰‹åŠ¨åˆ é™¤\n")

            logger.error(f"ğŸ“ æ—§ä½ç½®: {OLD_DATA_FILE}")
            logger.error(f"ğŸ“ æ–°ä½ç½®: {DATA_FILE}")
            logger.error("âœ… è¯åº“è¿ç§»å®Œæˆï¼æ—§æ•°æ®ä¿ç•™åœ¨åŸä½ç½®ï¼Œå¯æ‰‹åŠ¨åˆ é™¤")

        except Exception as e:
            logger.error(f"âŒ è¯åº“è¿ç§»å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            # ç»§ç»­æ‰§è¡Œä¸‹é¢çš„é»˜è®¤åˆå§‹åŒ–é€»è¾‘

    # === åŸæœ‰é€»è¾‘ï¼šåˆ›å»ºé»˜è®¤æ•°æ® ===
    if not os.path.exists(DATA_FILE):
        if os.path.exists(DEFAULT_DATA_FILE):
            # å¦‚æœ default.json å­˜åœ¨ï¼Œç›´æ¥å¤åˆ¶ä½œä¸ºåˆå§‹è¯åº“
            try:
                logger.error("ğŸ“¦ æ£€æµ‹åˆ°é»˜è®¤è¯åº“æ–‡ä»¶ï¼Œæ­£åœ¨åˆå§‹åŒ–...")
                shutil.copy2(DEFAULT_DATA_FILE, DATA_FILE)
                logger.error(f"âœ… é»˜è®¤è¯åº“å·²ä» {DEFAULT_DATA_FILE} åˆå§‹åŒ–åˆ° {DATA_FILE}")
            except Exception as e:
                logger.error(f"âŒ å¤åˆ¶é»˜è®¤è¯åº“å¤±è´¥: {str(e)}")
                # å¦‚æœå¤åˆ¶å¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„ç©ºç»“æ„
                fallback_data = {
                    "version": "1.6",
                    "last_modified": datetime.now().isoformat(),
                    "categories": [],
                    "settings": {
                        "language": "zh-CN",
                        "separator": ", ",
                        "save_selection": True
                    }
                }
                _atomic_save_json(DATA_FILE, fallback_data, create_backup=False)
                logger.info("ğŸ“ å·²åˆ›å»ºç©ºè¯åº“ç»“æ„ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
        else:
            # å¦‚æœ default.json ä¹Ÿä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„ç©ºç»“æ„
            fallback_data = {
                "version": "1.6",
                "last_modified": datetime.now().isoformat(),
                "categories": [],
                "settings": {
                    "language": "zh-CN",
                    "separator": ", ",
                    "save_selection": True
                }
            }
            _atomic_save_json(DATA_FILE, fallback_data, create_backup=False)
            logger.error("âš ï¸ é»˜è®¤è¯åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå·²åˆ›å»ºç©ºè¯åº“ç»“æ„")

    # === æ–°å¢ï¼šå‡çº§ç°æœ‰æ•°æ®æ–‡ä»¶ï¼Œæ·»åŠ æ—¶é—´æˆ³å­—æ®µ ===
    # å¦‚æœ data.json å·²å­˜åœ¨ï¼Œæ£€æŸ¥å¹¶æ·»åŠ ç¼ºå¤±çš„æ—¶é—´æˆ³å­—æ®µ
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)

            # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘ last_modified å­—æ®µ
            needs_upgrade = "last_modified" not in existing_data

            # æ£€æŸ¥åˆ†ç±»å’Œæç¤ºè¯æ˜¯å¦ç¼ºå°‘æ—¶é—´æˆ³
            for category in existing_data.get("categories", []):
                if "updated_at" not in category:
                    needs_upgrade = True
                    break
                for prompt in category.get("prompts", []):
                    if "updated_at" not in prompt:
                        needs_upgrade = True
                        break
                if needs_upgrade:
                    break

            # å¦‚æœéœ€è¦å‡çº§ï¼Œä½¿ç”¨ _ensure_data_compatibility æ·»åŠ æ—¶é—´æˆ³
            if needs_upgrade:
                logger.info("ğŸ“ æ£€æµ‹åˆ°æ•°æ®æ–‡ä»¶ç¼ºå°‘æ—¶é—´æˆ³å­—æ®µï¼Œæ­£åœ¨å‡çº§...")
                upgraded_data = _ensure_data_compatibility(existing_data)
                _atomic_save_json(DATA_FILE, upgraded_data, create_backup=True)
                logger.info("âœ… æ•°æ®æ–‡ä»¶å·²å‡çº§ï¼Œæ·»åŠ äº†æ—¶é—´æˆ³å­—æ®µ")

        except Exception as e:
            logger.error(f"âš ï¸ å‡çº§æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
            # ä¸å½±å“å¯åŠ¨ï¼Œç»§ç»­è¿è¡Œ

# åœ¨æ’ä»¶åŠ è½½æ—¶è°ƒç”¨åˆå§‹åŒ–
initialize_data_file()
