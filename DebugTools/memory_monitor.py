"""
å†…å­˜ç›‘æ§èŠ‚ç‚¹ - Memory Monitor Node
å®æ—¶ç›‘æ§ç³»ç»Ÿå†…å­˜å’ŒVRAMä½¿ç”¨æƒ…å†µï¼Œæä¾›å†…å­˜ä¼˜åŒ–å»ºè®®
"""

import sys
import os
import time
import torch
import psutil
import platform
from typing import Dict, Any, Optional

CATEGORY_TYPE = "Danbooru/Debug"


class MemoryMonitor:
    """
    å†…å­˜ç›‘æ§èŠ‚ç‚¹ - ç›‘æ§ç³»ç»Ÿå†…å­˜å’ŒVRAMä½¿ç”¨æƒ…å†µ
    """

    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "monitor_level": (["basic", "detailed", "full"], {
                    "default": "basic",
                    "tooltip": "ç›‘æ§çº§åˆ«ï¼šbasic=åŸºç¡€ä¿¡æ¯ï¼Œdetailed=è¯¦ç»†ä¿¡æ¯ï¼Œfull=å®Œæ•´ä¿¡æ¯"
                }),
                "auto_optimize": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦è‡ªåŠ¨æ‰§è¡Œå†…å­˜ä¼˜åŒ–"
                }),
                "warning_threshold": ("FLOAT", {
                    "default": 0.85,
                    "min": 0.5,
                    "max": 0.95,
                    "step": 0.05,
                    "tooltip": "å†…å­˜è­¦å‘Šé˜ˆå€¼ï¼ˆ0.5-0.95ï¼‰"
                })
            },
            "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("memory_report", "optimization_suggestions")
    FUNCTION = "monitor_memory"
    CATEGORY = CATEGORY_TYPE
    OUTPUT_NODE = True

    def monitor_memory(self, monitor_level, auto_optimize, warning_threshold, prompt=None, extra_pnginfo=None):
        """
        ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µå¹¶ç”ŸæˆæŠ¥å‘Š

        Args:
            monitor_level: ç›‘æ§çº§åˆ«
            auto_optimize: æ˜¯å¦è‡ªåŠ¨ä¼˜åŒ–
            warning_threshold: è­¦å‘Šé˜ˆå€¼

        Returns:
            å†…å­˜æŠ¥å‘Šå’Œä¼˜åŒ–å»ºè®®
        """
        try:
            print(f"[MemoryMonitor] ========== å¼€å§‹å†…å­˜ç›‘æ§ ==========")
            print(f"[MemoryMonitor] ç›‘æ§çº§åˆ«: {monitor_level}")
            print(f"[MemoryMonitor] è‡ªåŠ¨ä¼˜åŒ–: {auto_optimize}")
            print(f"[MemoryMonitor] è­¦å‘Šé˜ˆå€¼: {warning_threshold * 100:.1f}%")

            # æ”¶é›†ç³»ç»Ÿä¿¡æ¯
            system_info = self._get_system_info()
            memory_info = self._get_memory_info()
            vram_info = self._get_vram_info()

            # ç”ŸæˆæŠ¥å‘Š
            report = self._generate_report(system_info, memory_info, vram_info, monitor_level)

            # æ£€æŸ¥è­¦å‘ŠçŠ¶æ€
            warnings = self._check_warnings(memory_info, vram_info, warning_threshold)

            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            suggestions = self._generate_suggestions(memory_info, vram_info, warnings, auto_optimize)

            # è‡ªåŠ¨ä¼˜åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if auto_optimize:
                self._auto_optimize(memory_info, vram_info, warning_threshold)

            # åˆå¹¶æŠ¥å‘Š
            full_report = report
            if warnings:
                full_report += "\n\nâš ï¸ è­¦å‘Š:\n" + "\n".join(warnings)

            print(f"[MemoryMonitor] ========== ç›‘æ§å®Œæˆ ==========")
            print(f"[MemoryMonitor] ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡: {memory_info['percent']:.1f}%")
            print(f"[MemoryMonitor] VRAMä½¿ç”¨ç‡: {vram_info['percent']:.1f}%")

            return (full_report, suggestions)

        except Exception as e:
            error_msg = f"å†…å­˜ç›‘æ§å¤±è´¥: {str(e)}"
            print(f"[MemoryMonitor] [FAILED] {error_msg}")
            import traceback
            print(f"[MemoryMonitor] å †æ ˆè¿½è¸ª:\n{traceback.format_exc()}")

            return (f"ç›‘æ§å¤±è´¥: {error_msg}", "è¯·æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒå’ŒPyTorchå®‰è£…")

    def _get_system_info(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸåŸºæœ¬ä¿¡æ¯"""
        try:
            return {
                "platform": platform.system(),
                "processor": platform.processor(),
                "python_version": platform.python_version(),
                "torch_version": torch.__version__,
                "cuda_available": torch.cuda.is_available(),
                "cuda_device_count": torch.cuda.device_count() if torch.cuda.is_available() else 0
            }
        except Exception as e:
            print(f"[MemoryMonitor] è·å–ç³»ç»Ÿä¿¡æ¯å¤±è´¥: {str(e)}")
            return {}

    def _get_memory_info(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿå†…å­˜ä¿¡æ¯"""
        try:
            memory = psutil.virtual_memory()
            swap = psutil.swap_memory()

            return {
                "total_gb": memory.total / (1024**3),
                "available_gb": memory.available / (1024**3),
                "used_gb": memory.used / (1024**3),
                "percent": memory.percent,
                "swap_total_gb": swap.total / (1024**3),
                "swap_used_gb": swap.used / (1024**3),
                "swap_percent": swap.percent
            }
        except Exception as e:
            print(f"[MemoryMonitor] è·å–å†…å­˜ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {"percent": 0, "available_gb": 0, "total_gb": 0}

    def _get_vram_info(self) -> Dict[str, Any]:
        """è·å–VRAMä¿¡æ¯"""
        try:
            if not torch.cuda.is_available():
                return {"available_gb": 0, "used_gb": 0, "percent": 0, "device_name": "æ— CUDAè®¾å¤‡"}

            device = torch.cuda.current_device()
            props = torch.cuda.get_device_properties(device)

            total_memory = props.total_memory / (1024**3)
            reserved_memory = torch.cuda.memory_reserved(device) / (1024**3)
            allocated_memory = torch.cuda.memory_allocated(device) / (1024**3)

            # è®¡ç®—å¯ç”¨å†…å­˜ï¼ˆä¼°ç®—ï¼‰
            available_memory = total_memory - reserved_memory

            return {
                "device_name": props.name,
                "total_gb": total_memory,
                "allocated_gb": allocated_memory,
                "reserved_gb": reserved_memory,
                "available_gb": available_memory,
                "percent": (allocated_memory / total_memory) * 100 if total_memory > 0 else 0
            }
        except Exception as e:
            print(f"[MemoryMonitor] è·å–VRAMä¿¡æ¯å¤±è´¥: {str(e)}")
            return {"available_gb": 0, "used_gb": 0, "percent": 0, "device_name": "è·å–å¤±è´¥"}

    def _generate_report(self, system_info: Dict, memory_info: Dict, vram_info: Dict, level: str) -> str:
        """ç”Ÿæˆå†…å­˜ç›‘æ§æŠ¥å‘Š"""
        lines = ["ğŸ“Š å†…å­˜ç›‘æ§æŠ¥å‘Š", "=" * 30]

        # ç³»ç»Ÿä¿¡æ¯
        if system_info:
            lines.append("ğŸ–¥ï¸ ç³»ç»Ÿä¿¡æ¯:")
            lines.append(f"  æ“ä½œç³»ç»Ÿ: {system_info.get('platform', 'æœªçŸ¥')}")
            lines.append(f"  Pythonç‰ˆæœ¬: {system_info.get('python_version', 'æœªçŸ¥')}")
            lines.append(f"  PyTorchç‰ˆæœ¬: {system_info.get('torch_version', 'æœªçŸ¥')}")
            lines.append("")

        # ç³»ç»Ÿå†…å­˜
        if memory_info:
            lines.append("ğŸ’¾ ç³»ç»Ÿå†…å­˜:")
            lines.append(f"  æ€»å†…å­˜: {memory_info.get('total_gb', 0):.1f} GB")
            lines.append(f"  å¯ç”¨å†…å­˜: {memory_info.get('available_gb', 0):.1f} GB")
            lines.append(f"  å·²ç”¨å†…å­˜: {memory_info.get('used_gb', 0):.1f} GB ({memory_info.get('percent', 0):.1f}%)")

            if level in ["detailed", "full"]:
                lines.append(f"  äº¤æ¢å†…å­˜: {memory_info.get('swap_used_gb', 0):.1f}/{memory_info.get('swap_total_gb', 0):.1f} GB ({memory_info.get('swap_percent', 0):.1f}%)")
            lines.append("")

        # VRAMä¿¡æ¯
        if vram_info:
            lines.append("ğŸ® æ˜¾å­˜(VRAM):")
            lines.append(f"  è®¾å¤‡: {vram_info.get('device_name', 'æœªçŸ¥')}")
            lines.append(f"  æ€»æ˜¾å­˜: {vram_info.get('total_gb', 0):.1f} GB")

            if level in ["detailed", "full"]:
                lines.append(f"  å·²åˆ†é…: {vram_info.get('allocated_gb', 0):.1f} GB")
                lines.append(f"  å·²é¢„ç•™: {vram_info.get('reserved_gb', 0):.1f} GB")
                lines.append(f"  å¯ç”¨æ˜¾å­˜: {vram_info.get('available_gb', 0):.1f} GB")

            lines.append(f"  ä½¿ç”¨ç‡: {vram_info.get('percent', 0):.1f}%")
            lines.append("")

        # æ—¶é—´æˆ³
        lines.append(f"ğŸ•’ ç›‘æ§æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")

        return "\n".join(lines)

    def _check_warnings(self, memory_info: Dict, vram_info: Dict, threshold: float) -> list:
        """æ£€æŸ¥å†…å­˜è­¦å‘Š"""
        warnings = []

        # ç³»ç»Ÿå†…å­˜è­¦å‘Š
        if memory_info.get('percent', 0) > threshold * 100:
            warnings.append(f"ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_info.get('percent', 0):.1f}% (é˜ˆå€¼: {threshold*100:.1f}%)")

        if memory_info.get('available_gb', 0) < 2.0:
            warnings.append(f"å¯ç”¨å†…å­˜è¿‡ä½: {memory_info.get('available_gb', 0):.1f} GB")

        # VRAMè­¦å‘Š
        if vram_info.get('percent', 0) > threshold * 100:
            warnings.append(f"VRAMä½¿ç”¨ç‡è¿‡é«˜: {vram_info.get('percent', 0):.1f}% (é˜ˆå€¼: {threshold*100:.1f}%)")

        if vram_info.get('available_gb', 0) < 1.0:
            warnings.append(f"å¯ç”¨VRAMè¿‡ä½: {vram_info.get('available_gb', 0):.1f} GB")

        # äº¤æ¢å†…å­˜è­¦å‘Š
        if memory_info.get('swap_percent', 0) > 50:
            warnings.append(f"äº¤æ¢å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_info.get('swap_percent', 0):.1f}%")

        return warnings

    def _generate_suggestions(self, memory_info: Dict, vram_info: Dict, warnings: list, auto_optimize: bool) -> str:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = ["ğŸ’¡ å†…å­˜ä¼˜åŒ–å»ºè®®", "=" * 30]

        # ç³»ç»Ÿå†…å­˜å»ºè®®
        mem_percent = memory_info.get('percent', 0)
        if mem_percent > 80:
            suggestions.append("ğŸ”¥ ç³»ç»Ÿå†…å­˜ç´§æ€¥å»ºè®®:")
            suggestions.append("  1. ç«‹å³å…³é—­ä¸å¿…è¦çš„åº”ç”¨ç¨‹åº")
            suggestions.append("  2. é‡å¯ComfyUIæ¸…ç†å†…å­˜")
            suggestions.append("  3. è€ƒè™‘ä½¿ç”¨æ›´å°çš„æ¨¡å‹åˆ†è¾¨ç‡")
            suggestions.append("  4. å¯ç”¨ComfyUIçš„--lowvramæ¨¡å¼")
        elif mem_percent > 60:
            suggestions.append("âš ï¸ ç³»ç»Ÿå†…å­˜å»ºè®®:")
            suggestions.append("  1. å…³é—­åå°åº”ç”¨ç¨‹åº")
            suggestions.append("  2. ä½¿ç”¨è¾ƒå°çš„batch size")
            suggestions.append("  3. å®šæœŸé‡å¯ComfyUI")

        # VRAMå»ºè®®
        vram_percent = vram_info.get('percent', 0)
        if vram_percent > 85:
            suggestions.append("ğŸ® VRAMç´§æ€¥å»ºè®®:")
            suggestions.append("  1. å¯ç”¨--lowvramæˆ–--medvramæ¨¡å¼")
            suggestions.append("  2. ä½¿ç”¨è¾ƒå°çš„åˆ†è¾¨ç‡")
            suggestions.append("  3. å‡å°‘åŒæ—¶åŠ è½½çš„æ¨¡å‹æ•°é‡")
            suggestions.append("  4. å¯ç”¨æ¨¡å‹å¸è½½åŠŸèƒ½")
        elif vram_percent > 70:
            suggestions.append("ğŸ® VRAMå»ºè®®:")
            suggestions.append("  1. è€ƒè™‘ä½¿ç”¨--medvramæ¨¡å¼")
            suggestions.append("  2. ä¼˜åŒ–å·¥ä½œæµç¨‹å‡å°‘å†…å­˜å ç”¨")
            suggestions.append("  3. ä½¿ç”¨å†…å­˜é«˜æ•ˆçš„ç»„ä»¶")

        # é€šç”¨å»ºè®®
        suggestions.append("ğŸ”§ é€šç”¨ä¼˜åŒ–å»ºè®®:")
        suggestions.append("  1. å®šæœŸæ¸…ç†ComfyUIç¼“å­˜")
        suggestions.append("  2. ä½¿ç”¨æ™ºèƒ½å†…å­˜ç®¡ç†")
        suggestions.append("  3. é¿å…åŒæ—¶è¿è¡Œå¤šä¸ªå¤§å‹å·¥ä½œæµ")
        suggestions.append("  4. ç›‘æ§å†…å­˜ä½¿ç”¨è¶‹åŠ¿")

        if warnings:
            suggestions.append(f"\nâš ï¸ å‘ç° {len(warnings)} ä¸ªå†…å­˜è­¦å‘Šéœ€è¦å¤„ç†")

        if auto_optimize:
            suggestions.append(f"\nâœ… è‡ªåŠ¨ä¼˜åŒ–å·²å¯ç”¨ï¼Œå°†è‡ªåŠ¨æ‰§è¡Œå†…å­˜æ¸…ç†")

        return "\n".join(suggestions)

    def _auto_optimize(self, memory_info: Dict, vram_info: Dict, threshold: float):
        """æ‰§è¡Œè‡ªåŠ¨å†…å­˜ä¼˜åŒ–"""
        try:
            optimized = False

            # ç³»ç»Ÿå†…å­˜è¿‡é«˜æ—¶æ‰§è¡Œæ¸…ç†
            if memory_info.get('percent', 0) > threshold * 100:
                print(f"[MemoryMonitor] æ‰§è¡Œç³»ç»Ÿå†…å­˜ä¼˜åŒ–...")

                # æ¸…ç†Pythonåƒåœ¾å›æ”¶
                import gc
                collected = gc.collect()
                print(f"[MemoryMonitor] åƒåœ¾å›æ”¶æ¸…ç†äº† {collected} ä¸ªå¯¹è±¡")

                # æ¸…ç†CUDAç¼“å­˜
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    print(f"[MemoryMonitor] å·²æ¸…ç†CUDAç¼“å­˜")

                optimized = True

            # VRAMè¿‡é«˜æ—¶æ‰§è¡ŒVRAMæ¸…ç†
            if vram_info.get('percent', 0) > threshold * 100:
                print(f"[MemoryMonitor] æ‰§è¡ŒVRAMä¼˜åŒ–...")

                if torch.cuda.is_available():
                    # å¼ºåˆ¶æ¸…ç†CUDAç¼“å­˜
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                    print(f"[MemoryMonitor] å·²å¼ºåˆ¶æ¸…ç†VRAM")

                optimized = True

            if optimized:
                print(f"[MemoryMonitor] âœ… è‡ªåŠ¨å†…å­˜ä¼˜åŒ–å®Œæˆ")
            else:
                print(f"[MemoryMonitor] â„¹ï¸ å†…å­˜ä½¿ç”¨æ­£å¸¸ï¼Œæ— éœ€ä¼˜åŒ–")

        except Exception as e:
            print(f"[MemoryMonitor] è‡ªåŠ¨ä¼˜åŒ–å¤±è´¥: {str(e)}")


# èŠ‚ç‚¹æ˜ å°„
def get_node_class_mappings():
    return {
        "MemoryMonitor": MemoryMonitor
    }

def get_node_display_name_mappings():
    return {
        "MemoryMonitor": "å†…å­˜ç›‘æ§å™¨ (Memory Monitor)"
    }

NODE_CLASS_MAPPINGS = get_node_class_mappings()
NODE_DISPLAY_NAME_MAPPINGS = get_node_display_name_mappings()


# æµ‹è¯•å‡½æ•°
def test_memory_monitor():
    """æµ‹è¯•å†…å­˜ç›‘æ§èŠ‚ç‚¹"""
    print(f"[MemoryMonitor.TEST] ========== æµ‹è¯•å†…å­˜ç›‘æ§èŠ‚ç‚¹ ==========")

    try:
        monitor = MemoryMonitor()

        # æµ‹è¯•åŸºç¡€ç›‘æ§
        print(f"[MemoryMonitor.TEST] ----- æµ‹è¯•åŸºç¡€ç›‘æ§ -----")
        report, suggestions = monitor.monitor_memory("basic", False, 0.85)
        print(f"[MemoryMonitor.TEST] åŸºç¡€ç›‘æ§æŠ¥å‘Šé•¿åº¦: {len(report)} å­—ç¬¦")
        print(f"[MemoryMonitor.TEST] å»ºè®®é•¿åº¦: {len(suggestions)} å­—ç¬¦")

        # æµ‹è¯•è¯¦ç»†ç›‘æ§
        print(f"[MemoryMonitor.TEST] ----- æµ‹è¯•è¯¦ç»†ç›‘æ§ -----")
        report, suggestions = monitor.monitor_memory("detailed", True, 0.8)
        print(f"[MemoryMonitor.TEST] è¯¦ç»†ç›‘æ§æŠ¥å‘Šé•¿åº¦: {len(report)} å­—ç¬¦")

        print(f"[MemoryMonitor.TEST] [SUCCESS] å†…å­˜ç›‘æ§èŠ‚ç‚¹æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"[MemoryMonitor.TEST] [FAILED] æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        print(f"[MemoryMonitor.TEST] å †æ ˆè¿½è¸ª:\n{traceback.format_exc()}")
        return False


if __name__ == "__main__":
    print(f"[MemoryMonitor] ========== å†…å­˜ç›‘æ§æ¨¡å—åŠ è½½å®Œæˆ ==========")
    print(f"[MemoryMonitor] èŠ‚ç‚¹ä¿¡æ¯:")
    print(f"[MemoryMonitor]   - èŠ‚ç‚¹ç±»: MemoryMonitor")
    print(f"[MemoryMonitor]   - æ˜¾ç¤ºåç§°: å†…å­˜ç›‘æ§å™¨ (Memory Monitor)")
    print(f"[MemoryMonitor]   - ç±»åˆ«: {CATEGORY_TYPE}")
    print(f"[MemoryMonitor]   - åŠŸèƒ½: monitor_memory")
    print(f"[MemoryMonitor] ========== æ¨¡å—ä¿¡æ¯å®Œæˆ ==========")

    # è¿è¡Œæµ‹è¯•
    test_result = test_memory_monitor()
    if test_result:
        print(f"[MemoryMonitor] [SUCCESS] è‡ªæµ‹è¯•é€šè¿‡ï¼Œå†…å­˜ç›‘æ§èŠ‚ç‚¹å·²å‡†å¤‡å°±ç»ª")
    else:
        print(f"[MemoryMonitor] [FAILED] è‡ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥èŠ‚ç‚¹å®ç°")