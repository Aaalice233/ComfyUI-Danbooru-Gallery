"""
å›¾åƒç¼“å­˜ä¿å­˜èŠ‚ç‚¹ - Image Cache Save Node
å°†å›¾åƒæ•°æ®ç¼“å­˜åˆ°æŒ‡å®šé€šé“ï¼Œä¾›è·å–èŠ‚ç‚¹ä¸»åŠ¨è¯»å–
"""

import sys
import os
import time
import torch
import numpy as np
from PIL import Image
from typing import List, Dict, Any, Optional, Tuple
from ..image_cache_manager.image_cache_manager import cache_manager

CATEGORY_TYPE = "danbooru"


class AnyType(str):
    """ç”¨äºè¡¨ç¤ºä»»æ„ç±»å‹çš„ç‰¹æ®Šç±»ï¼Œåœ¨ç±»å‹æ¯”è¾ƒæ—¶æ€»æ˜¯è¿”å›ç›¸ç­‰"""
    def __eq__(self, _) -> bool:
        return True

    def __ne__(self, __value: object) -> bool:
        return False


any_typ = AnyType("*")


# å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹ - ä»å…±äº«æ¨¡å—å¯¼å…¥
# cache_manager = ImageCacheManager()


class ImageCache:
    """
    å›¾åƒç¼“å­˜ä¿å­˜èŠ‚ç‚¹ - å°†å›¾åƒç¼“å­˜åˆ°æŒ‡å®šé€šé“ä¾›å…¶ä»–èŠ‚ç‚¹è·å–
    """

    # ç±»çº§åˆ«çš„ç¼“å­˜ï¼šå­˜å‚¨æ£€æµ‹ç»“æœï¼Œæ‰€æœ‰å®ä¾‹å…±äº«
    _has_manager_cache = None  # Noneè¡¨ç¤ºæœªæ£€æµ‹ï¼ŒTrue/Falseè¡¨ç¤ºæ£€æµ‹ç»“æœ
    _warning_sent_cache = False  # ç±»çº§åˆ«çš„è­¦å‘Šå‘é€æ ‡å¿—

    def __init__(self):
        pass

    @classmethod
    def _check_for_group_executor_manager(cls, prompt: Optional[Dict]) -> bool:
        """
        æ£€æµ‹å·¥ä½œæµä¸­æ˜¯å¦æœ‰GroupExecutorManagerèŠ‚ç‚¹
        ä½¿ç”¨ç±»çº§åˆ«ç¼“å­˜ï¼Œåªåœ¨ç¬¬ä¸€æ¬¡æ‰§è¡Œæ—¶æ£€æµ‹

        Args:
            prompt: å·¥ä½œæµæ•°æ®

        Returns:
            bool: æ˜¯å¦å­˜åœ¨GroupExecutorManagerèŠ‚ç‚¹
        """
        # å¦‚æœå·²ç»ç¼“å­˜äº†æ£€æµ‹ç»“æœï¼Œç›´æ¥è¿”å›
        if cls._has_manager_cache is not None:
            return cls._has_manager_cache

        # ç¬¬ä¸€æ¬¡æ£€æµ‹
        if not prompt:
            cls._has_manager_cache = False
            return False

        try:
            # promptæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å·¥ä½œæµæ•°æ®å­—å…¸
            workflow_data = prompt[0] if isinstance(prompt, list) and len(prompt) > 0 else prompt

            # éå†å·¥ä½œæµä¸­çš„æ‰€æœ‰èŠ‚ç‚¹
            if isinstance(workflow_data, dict):
                for node_id, node_data in workflow_data.items():
                    if isinstance(node_data, dict) and node_data.get("class_type") == "GroupExecutorManager":
                        print(f"[ImageCacheSave] âœ“ æ£€æµ‹åˆ°GroupExecutorManagerèŠ‚ç‚¹ï¼ˆå·²ç¼“å­˜ï¼‰")
                        cls._has_manager_cache = True
                        return True

            print(f"[ImageCacheSave] âš  æœªæ£€æµ‹åˆ°GroupExecutorManagerèŠ‚ç‚¹ï¼ˆå·²ç¼“å­˜ï¼‰")
            cls._has_manager_cache = False
            return False
        except Exception as e:
            print(f"[ImageCacheSave] æ£€æµ‹GroupExecutorManagerå¤±è´¥: {str(e)}")
            cls._has_manager_cache = False
            return False

    @classmethod
    def _send_no_manager_warning(cls):
        """å‘é€WebSocketè­¦å‘Šåˆ°å‰ç«¯ï¼ˆç±»çº§åˆ«ï¼Œåªå‘é€ä¸€æ¬¡ï¼‰"""
        if cls._warning_sent_cache:
            return  # é¿å…é‡å¤å‘é€

        try:
            from server import PromptServer
            PromptServer.instance.send_sync("cache-node-no-manager-warning", {
                "node_type": "ImageCacheSave",
                "message": "å›¾åƒç¼“å­˜èŠ‚ç‚¹éœ€è¦é…åˆç»„æ‰§è¡Œç®¡ç†å™¨ä½¿ç”¨ï¼Œè¯·æ·»åŠ ç»„æ‰§è¡Œç®¡ç†å™¨å’Œè§¦å‘å™¨ååˆ·æ–°ç½‘é¡µ\nImage cache nodes require Group Executor Manager. Please add Manager and Trigger, then refresh."
            })
            cls._warning_sent_cache = True
            print(f"[ImageCacheSave] å·²å‘é€WebSocketè­¦å‘Š")
        except ImportError:
            print("[ImageCacheSave] è­¦å‘Š: ä¸åœ¨ComfyUIç¯å¢ƒä¸­ï¼Œè·³è¿‡WebSocketé€šçŸ¥")
        except Exception as e:
            print(f"[ImageCacheSave] WebSocketè­¦å‘Šå‘é€å¤±è´¥: {e}")

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE", {"tooltip": "è¦ç¼“å­˜çš„å›¾åƒ"}),
            },
            "optional": {
                "enable_preview": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ§åˆ¶æ˜¯å¦ç”Ÿæˆç¼“å­˜å›¾åƒçš„é¢„è§ˆ"
                })
            },
            "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"},
        }

    RETURN_TYPES = ()
    FUNCTION = "cache_images"
    CATEGORY = CATEGORY_TYPE
    INPUT_IS_LIST = True
    OUTPUT_NODE = True

    def cache_images(self,
                    images: List,
                    prompt: Optional[Dict] = None,
                    extra_pnginfo: Optional[Dict] = None,
                    enable_preview: List[bool] = [True]) -> Dict[str, Any]:
        """
        å°†å›¾åƒç¼“å­˜åˆ°å…¨å±€ç¼“å­˜ï¼ˆé…åˆGroupExecutorManagerä½¿ç”¨ï¼‰

        é‡è¦ï¼šæ­¤èŠ‚ç‚¹å¿…é¡»é…åˆGroupExecutorManagerä½¿ç”¨
        - ä¿å­˜å‰å›ºå®šæ¸…ç©ºæ‰€æœ‰ç¼“å­˜
        - ä¿å­˜åˆ°å…¨å±€ç¼“å­˜ï¼ˆä¸ä½¿ç”¨é€šé“éš”ç¦»ï¼‰
        - æ‰§è¡Œé¡ºåºç”±GroupExecutorManageræ§åˆ¶
        """
        try:
            timestamp = time.strftime("%H:%M:%S", time.localtime())
            print(f"\n{'='*60}")
            print(f"[ImageCacheSave] â° æ‰§è¡Œæ—¶é—´: {timestamp}")
            print(f"[ImageCacheSave] ğŸ” å½“å‰ç»„å: {cache_manager.current_group_name}")
            print(f"[ImageCacheSave] ğŸ“ ä½¿ç”¨å…¨å±€ç¼“å­˜ï¼ˆä¸éš”ç¦»é€šé“ï¼‰")
            print(f"[ImageCacheSave] â”Œâ”€ å¼€å§‹ä¿å­˜å›¾åƒ")
            print(f"{'='*60}\n")

            # âœ… æ£€æµ‹å·¥ä½œæµä¸­æ˜¯å¦æœ‰GroupExecutorManagerèŠ‚ç‚¹ï¼ˆä½¿ç”¨ç¼“å­˜ï¼Œåªæ£€æµ‹ä¸€æ¬¡ï¼‰
            has_manager = ImageCache._check_for_group_executor_manager(prompt)
            if not has_manager:
                # å‘é€WebSocketäº‹ä»¶åˆ°å‰ç«¯æ˜¾ç¤ºtoastï¼ˆåªå‘é€ä¸€æ¬¡ï¼‰
                ImageCache._send_no_manager_warning()

            # å‚æ•°å¤„ç† - ç¡®ä¿æ­£ç¡®æå–å‚æ•°å€¼
            processed_enable_preview = enable_preview[0] if isinstance(enable_preview, list) else enable_preview

            # âœ… ä¿å­˜å‰å›ºå®šæ¸…ç©ºæ‰€æœ‰ç¼“å­˜
            # å› ä¸ºæ­¤èŠ‚ç‚¹å¿…é¡»é…åˆGroupExecutorManagerä½¿ç”¨ï¼Œæ¯ä¸ªç»„ä¿å­˜æ—¶éƒ½åº”æ¸…ç©ºå‰ä¸€ä¸ªç»„çš„ç¼“å­˜
            print(f"[ImageCacheSave] ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰ç¼“å­˜é€šé“ï¼ˆå¼ºåˆ¶æ‰§è¡Œï¼‰")
            cache_manager.clear_cache(channel_name=None)  # Noneè¡¨ç¤ºæ¸…ç©ºæ‰€æœ‰é€šé“

            # å°†è¾“å…¥çš„æ‰¹æ¬¡åˆ—è¡¨å±•å¼€ä¸ºå•ä¸ªå›¾åƒå¼ é‡åˆ—è¡¨
            # ComfyUI's INPUT_IS_LIST=True wraps inputs in a list.
            # Each item in the list is a batch tensor (B, H, W, C).
            # We need to unpack all batches into a single flat list of images for the manager.
            unpacked_images = []
            for batch in images:
                unpacked_images.extend(list(batch))  # Iterating over a tensor unpacks the first dimension

            # âœ… å…³é”®ä¿®å¤ï¼šä¿å­˜åˆ°å…¨å±€é»˜è®¤é€šé“ï¼ˆchannel_name="__global__"ï¼‰è€Œéç»„åé€šé“
            # è¿™æ ·æ‰€æœ‰ç»„éƒ½ä»åŒä¸€ä¸ªç¼“å­˜è¯»å†™ï¼Œç”±GroupExecutorManageræ§åˆ¶æ‰§è¡Œé¡ºåº
            results = cache_manager.cache_images(
                images=unpacked_images,
                filename_prefix="cached_image",
                preview_rgba=True,
                clear_before_save=False,  # å·²ç»åœ¨ä¸Šé¢æ¸…ç©ºè¿‡äº†
                channel_name="__global__"  # ä½¿ç”¨å…¨å±€é€šé“
            )

            print(f"[ImageCacheSave] â””â”€ ä¿å­˜å®Œæˆ: {len(results)} å¼ ")

            if processed_enable_preview:
                return {"ui": {"images": results}}
            else:
                return {"ui": {"images": []}}

        except Exception as e:
            print(f"[ImageCacheSave] â””â”€ âœ— ä¿å­˜å¤±è´¥: {str(e)}")
            import traceback
            print(traceback.format_exc())

            # è¿”å›ç©ºç»“æœä½†ä¸æŠ›å‡ºå¼‚å¸¸
            return {"ui": {"images": []}}


# èŠ‚ç‚¹æ˜ å°„
def get_node_class_mappings():
    return {
        "ImageCacheSave": ImageCache
    }

def get_node_display_name_mappings():
    return {
        "ImageCacheSave": "å›¾åƒç¼“å­˜ä¿å­˜ (Image Cache Save)"
    }

NODE_CLASS_MAPPINGS = get_node_class_mappings()
NODE_DISPLAY_NAME_MAPPINGS = get_node_display_name_mappings()